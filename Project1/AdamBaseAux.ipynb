{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import torch\n",
    "import various_data_functions\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "from torch.nn import functional as F\n",
    "import dlc_practical_prologue as prologue\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Setting plot parameters\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "#Number of data points\n",
    "N=10**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base functions adapted from the practicals\n",
    "def train_model(model, train_input, train_target,train_classes, mini_batch_size, test_input=None, test_target=None, crit=nn.CrossEntropyLoss, eta = 1e-3, nb_epochs = 50,print_=False, store_loss = False, aux_factor=1, store_error=False, checkpoint_name=None):\n",
    "    #Initializing the loss, the optimizer, and the stored loss and errors for the plots\n",
    "    criterion = crit()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=eta)\n",
    "    stored_loss = []\n",
    "    stored_error = []\n",
    "    \n",
    "    #Retrieving data if a similar model has already been trained or partially trained\n",
    "    nb_epochs_finished = 0\n",
    "    if checkpoint_name!=None:\n",
    "        try:\n",
    "            checkpoint = torch.load(checkpoint_name)\n",
    "            nb_epochs_finished = checkpoint['nb_epochs_finished']\n",
    "            model.load_state_dict(checkpoint['model_state'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "            if print_:\n",
    "                print(f'Checkpoint loaded with {nb_epochs_finished} epochs finished.')\n",
    "            stored_loss=checkpoint['stored_loss']\n",
    "            if len(stored_loss)>nb_epochs*3:\n",
    "                stored_loss=stored_loss[0:nb_epochs*3]\n",
    "            stored_error=checkpoint['stored_error']\n",
    "            if len(stored_error)>nb_epochs:\n",
    "                stored_error=stored_error[0:nb_epochs]\n",
    "        except FileNotFoundError:\n",
    "            if print_:\n",
    "                print('Starting from scratch.')\n",
    "        except:\n",
    "            print('Error when loading the checkpoint.')\n",
    "            exit(1)\n",
    "    \n",
    "    #Training the network if the checkpoint wasn't fully trained\n",
    "    for e in range(nb_epochs_finished,nb_epochs):\n",
    "        \n",
    "        #Initializing accumulated losses\n",
    "        #loss1 is the loss over the output (identifying which number is greater)\n",
    "        #loss2 and loss3 are the auxiliary losses trying to identify the numbers in the 2 input pictures\n",
    "        acc_loss = 0\n",
    "        acc_loss1 = 0\n",
    "        acc_loss2 = 0\n",
    "        acc_loss3 = 0\n",
    "        \n",
    "        #permuting the samples\n",
    "        permuted_index = torch.randperm(train_input.size()[0])\n",
    "        train_input_shuffled = train_input[permuted_index]\n",
    "        train_target_shuffled = train_target[permuted_index]\n",
    "        train_classes_shuffled = train_classes[permuted_index]\n",
    "        \n",
    "        \n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            \n",
    "            #forward pass\n",
    "            output,aux_output = model(train_input_shuffled.narrow(0, b, mini_batch_size))\n",
    "            if crit==nn.MSELoss:\n",
    "                \n",
    "                #computing the different losses\n",
    "                loss1 = criterion(output[:,1], train_target_shuffled.narrow(0, b, mini_batch_size))\n",
    "                loss2 = criterion(torch.argmax(aux_output[:,0:9],dim=1), train_classes_shuffled[:,0].narrow(0, b, mini_batch_size))\n",
    "                loss3 = criterion(torch.argmax(aux_output[:,10:19],dim=1), train_classes_shuffled[:,1].narrow(0, b, mini_batch_size))\n",
    "                loss = loss1 + loss2 + loss3\n",
    "                print('|| loss1 req grad =', loss1.requires_grad, '|| loss2 req grad =',loss2.requires_grad,'|| loss3 req grad =', loss3.requires_grad)\n",
    "            elif crit==nn.CrossEntropyLoss:\n",
    "                loss1 = criterion(output, train_target_shuffled.narrow(0, b, mini_batch_size))\n",
    "                loss2 = criterion(aux_output[:,:10], train_classes_shuffled[:,0].narrow(0, b, mini_batch_size))\n",
    "                loss3 = criterion(aux_output[:,10:], train_classes_shuffled[:,1].narrow(0, b, mini_batch_size))\n",
    "                loss = loss1 + aux_factor*(loss2 + loss3)\n",
    "            else:\n",
    "                print(\"Loss not implemented\")\n",
    "                \n",
    "            #Update the accumulated losses\n",
    "            acc_loss = acc_loss + loss.item()\n",
    "            acc_loss1 = acc_loss1 + loss1.item()\n",
    "            acc_loss2 = acc_loss2 + loss2.item()\n",
    "            acc_loss3 = acc_loss3 + loss3.item()\n",
    "            \n",
    "            #zero the gradients\n",
    "            model.zero_grad()\n",
    "            \n",
    "            #backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            #optimizer step\n",
    "            optimizer.step()\n",
    "            \n",
    "        #update the stored losses and error if needed\n",
    "        if store_loss:\n",
    "            stored_loss += [[acc_loss1], [acc_loss2], [acc_loss3]]\n",
    "        if store_error:\n",
    "            stored_error +=[compute_nb_errors(model, test_input, test_target, mini_batch_size)]\n",
    "            \n",
    "        #print the different losses if needed\n",
    "        if print_:\n",
    "            print(e, 'tot loss', acc_loss, 'loss1', acc_loss1, 'loss2', acc_loss2, 'loss3', acc_loss3)\n",
    "            \n",
    "        #save the checkpoint for later if needed\n",
    "        if checkpoint_name!=None:\n",
    "                checkpoint = {'nb_epochs_finished': e + 1,'model_state': model.state_dict(),'optimizer_state': optimizer.state_dict(),'stored_loss':stored_loss,'stored_error':stored_error}\n",
    "                torch.save(checkpoint, checkpoint_name)\n",
    "        \n",
    "    #return the stored quantities  \n",
    "    return torch.tensor(stored_loss),torch.tensor(stored_error)\n",
    "\n",
    "#error computing function\n",
    "def compute_nb_errors(model, input, target, mini_batch_size=100):\n",
    "    nb_errors = 0\n",
    "\n",
    "    for b in range(0, input.size(0), mini_batch_size):\n",
    "        output , aux_output = model(input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = output.max(1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if target[b + k]!=predicted_classes[k]:\n",
    "                nb_errors = nb_errors + 1\n",
    "\n",
    "    return nb_errors\n",
    "\n",
    "#this function lets us do multiple runs more easily\n",
    "def run_many_times(model,crit=nn.CrossEntropyLoss,mini_batch_size=100,n=10,print_=True,eta=1e-3,nb_epochs=25,aux_factor=0,shuffle=True, store_error=False,checkpoint_name=None):\n",
    "    average_error=0\n",
    "    losses=torch.empty(0,nb_epochs,3)\n",
    "    errors=torch.empty(0,nb_epochs)\n",
    "    for i in range(n):\n",
    "        m=model()\n",
    "        train_input,train_target,train_classes,test_input,test_target,test_classes=various_data_functions.data(N,True,False,nn.CrossEntropyLoss,shuffle=shuffle)\n",
    "        if checkpoint_name!=None:\n",
    "            checkpoint_name_spec=checkpoint_name+'try_'+str(i)+'.pth'\n",
    "        else:\n",
    "            checkpoint_name_spec=None\n",
    "        new_losses,new_errors=train_model(m, train_input, train_target,train_classes,mini_batch_size,test_input=test_input, test_target=test_target,crit=crit,eta=eta,nb_epochs=nb_epochs,aux_factor=aux_factor,store_loss=True,store_error=store_error,checkpoint_name=checkpoint_name_spec)\n",
    "        new_losses=new_losses.view(1,nb_epochs, 3)\n",
    "        if store_error:\n",
    "            new_errors= new_errors.view(1,nb_epochs)\n",
    "            errors = torch.cat((errors,new_errors),0)\n",
    "        if print_:\n",
    "            losses = torch.cat((losses, new_losses), 0)\n",
    "            nb_test_errors = compute_nb_errors(m, test_input, test_target, mini_batch_size)\n",
    "            print('test error Net {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                      nb_test_errors, test_input.size(0)))\n",
    "            average_error+=(100 * nb_test_errors) / test_input.size(0)\n",
    "    if print_:\n",
    "        print(\"Average error: \"+str(average_error/n))\n",
    "        avg_losses=torch.sum(losses,0)/n\n",
    "        mod=int(torch.floor(torch.Tensor([nb_epochs/25])))\n",
    "        fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True)\n",
    "        x_lab=torch.arange(nb_epochs)\n",
    "        x_labels=x_lab[x_lab%mod==0].detach().numpy()\n",
    "        ax0.errorbar(x_labels, avg_losses[x_lab%mod==0,0].detach().numpy(), yerr=torch.std(losses[:,:,0],0)[x_lab%mod==0].detach().numpy(), fmt='-o')\n",
    "        ax0.set_title('evolution of the cross entropy loss')\n",
    "        ax1.errorbar(x_labels, avg_losses[x_lab%mod==0,1].detach().numpy(), yerr=torch.std(losses[:,:,1],0)[x_lab%mod==0].detach().numpy(), fmt='o')\n",
    "        ax1.errorbar(x_labels, avg_losses[x_lab%mod==0,2].detach().numpy(), yerr=torch.std(losses[:,:,2],0)[x_lab%mod==0].detach().numpy(), fmt='o')\n",
    "        ax1.set_title('evolution of the auxiliary losses')\n",
    "        plt.show()\n",
    "    if store_error:\n",
    "        return errors\n",
    "\n",
    "#this function returns the number of parameters of a model\n",
    "def n_params(model):\n",
    "    n = 0\n",
    "    for params in model.parameters():\n",
    "        n += params.numel()\n",
    "    return n\n",
    "\n",
    "#this function uses the previous ones to build a big plot with several models\n",
    "def big_error_plot(models,model_names,n=50,nb_epochs=100,eta=1e-3,div=25,name=\"big_error_plot.png\",aux_factor=1):\n",
    "    x_lab=torch.arange(nb_epochs)\n",
    "    mod=int(torch.floor(torch.Tensor([nb_epochs/div])))\n",
    "    x_labels=x_lab[x_lab%mod==0].detach().numpy()\n",
    "    for i in range(len(models)):\n",
    "        print(\"Starting model \" + model_names[i])\n",
    "        errors=run_many_times(models[i],crit=nn.CrossEntropyLoss,mini_batch_size=10,n=n,print_=False,eta=eta,nb_epochs=nb_epochs,aux_factor=aux_factor,shuffle=True, store_error=True,checkpoint_name='checkpoints/'+model_names[i]+'_'+str(aux_factor).replace('.','')+'_')\n",
    "        #sns.relplot(x=\"timepoint\", y=\"signal\", col=\"region\",hue=\"event\", style=\"event\", kind=\"line\",)\n",
    "        #plt.errorbar(x_labels,(errors.mean(dim=0)[x_lab%mod==0]/10).detach().numpy(),yerr=(torch.std(errors,dim=0)[x_lab%mod==0]/10).detach().numpy(),fmt='o')\n",
    "        mean=(errors.mean(dim=0)[x_lab%mod==0]/10).detach().numpy()\n",
    "        std=(torch.std(errors,dim=0)[x_lab%mod==0]/10).detach().numpy()\n",
    "        plt.plot(x_labels,mean)\n",
    "        plt.fill_between(x_labels,mean-std,mean+std,alpha=0.5)\n",
    "        print('Mean number of errors after '+str(nb_epochs)+' epochs of training: '+str(errors.mean(dim=0)[-1])+' out of 1000 test samples with a standard deviation of '+str(torch.std(errors,dim=0)[-1]))\n",
    "    plt.ylabel('Accuracy[%]')\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.legend(model_names)\n",
    "    plt.savefig(name,bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = True\n",
    "train_input,train_target,train_classes,test_input,test_target,test_classes=various_data_functions.data(N,True,False,nn.CrossEntropyLoss,shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3328)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after = (14-3+1)/3\n",
    "int(after), int(after**2*208)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C1L2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "                \n",
    "        #convolutions.\n",
    "        self.conv1 = nn.Conv2d(2, 208, kernel_size=3,groups=2)\n",
    "        \n",
    "        #define the half lenght of the output (linearized) after the last convolution\n",
    "        self.h = int(4**2*208/2)\n",
    "        \n",
    "        #linear layers for the auxiliary losses\n",
    "        self.aux_linear1 = nn.Linear(self.h, 10)\n",
    "        self.aux_linear2 = nn.Linear(self.h, 10)\n",
    "        \n",
    "        #linear layers for the final output\n",
    "        self.fc1 = nn.Linear(2*self.h, 20)\n",
    "        self.fc2 = nn.Linear(20, 2)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #computing the convolution\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = x.view(-1, 2*self.h)\n",
    "        \n",
    "        #computing the linear+softmax to make the auxiliary output\n",
    "        #deviding the tensor \n",
    "        a1 = x.narrow(1, 0,      self.h)\n",
    "        a2 = x.narrow(1, self.h, self.h)\n",
    "                \n",
    "        #computing the auxiliary output\n",
    "        a1 = F.softmax(self.aux_linear1(a1), dim = 1).unsqueeze(1)\n",
    "        a2 = F.softmax(self.aux_linear2(a2), dim = 1).unsqueeze(1)\n",
    "        #merging the vector to return the final auxiliary output\n",
    "        aux_output = torch.cat((a1, a2), 1)\n",
    "        \n",
    "        #computing the layers for the final output\n",
    "        x = F.relu(self.fc1(x))\n",
    "        output = F.softmax(self.fc2(x), dim=1)\n",
    "        return output, aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 2]), torch.Size([5, 2, 10]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checks\n",
    "model = C1L2()\n",
    "x = train_input[0:5]\n",
    "output, aux_output = model(x)\n",
    "output.shape, aux_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C1L3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #convolutions\n",
    "        self.conv1 = nn.Conv2d(2, 32, kernel_size=3,groups=2)\n",
    "        \n",
    "        #define the half lenght of the output (linearized) after the last convolution\n",
    "        self.h = int(4**2*32/2)\n",
    "        \n",
    "        #linear layers for the auxiliary losses\n",
    "        self.aux_linear1 = nn.Linear(self.h, 10)\n",
    "        self.aux_linear2 = nn.Linear(self.h, 10)\n",
    "        \n",
    "        #linear layers for the final output\n",
    "        self.fc1 = nn.Linear(2*self.h, 128)\n",
    "        self.fc2 = nn.Linear(128, 20)\n",
    "        self.fc3 = nn.Linear(20, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #computing the convolution\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = x.view(-1, 2*self.h)\n",
    "        \n",
    "        #computing the linear+softmax to make the auxiliary output\n",
    "        #deviding the tensor \n",
    "        a1 = x.narrow(1, 0,      self.h)\n",
    "        a2 = x.narrow(1, self.h, self.h)\n",
    "                \n",
    "        #computing the output\n",
    "        a1 = F.softmax(self.aux_linear1(a1), dim = 1).unsqueeze(1)\n",
    "        a2 = F.softmax(self.aux_linear2(a2), dim = 1).unsqueeze(1)\n",
    "        #merging the vector to return the final auxiliary output\n",
    "        aux_output = torch.cat((a1, a2), 1)\n",
    "        \n",
    "        #computing the layers for the final output\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        output = F.softmax(self.fc3(x),dim=1)\n",
    "        return output, aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 2]), torch.Size([5, 2, 10]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checks\n",
    "model = C1L3()\n",
    "x = train_input[0:5]\n",
    "output, aux_output = model(x)\n",
    "output.shape, aux_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4**2*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C1L5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #convolutions.\n",
    "        self.conv1 = nn.Conv2d(2, 20, kernel_size=3,groups=2)\n",
    "        \n",
    "        #define the half lenght of the output (linearized) after the last convolution\n",
    "        self.h = int(4**2*20/2)\n",
    "        \n",
    "        #linear layers for the auxiliary losses\n",
    "        self.aux_linear1 = nn.Linear(self.h, 10)\n",
    "        self.aux_linear2 = nn.Linear(self.h, 10)\n",
    "        \n",
    "        #linear layers for the final output\n",
    "        self.fc1 = nn.Linear(2*self.h, 160)\n",
    "        self.fc2 = nn.Linear(160, 80)\n",
    "        self.fc3 = nn.Linear(80,40)\n",
    "        self.fc4 = nn.Linear(40,20)\n",
    "        self.fc5 = nn.Linear(20, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #computing the convolution\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = x.view(-1, 2*self.h)\n",
    "        \n",
    "        #computing the linear+softmax to make the auxiliary output\n",
    "        #deviding the tensor \n",
    "        a1 = x.narrow(1, 0,      self.h)\n",
    "        a2 = x.narrow(1, self.h, self.h)\n",
    "                \n",
    "        #computing auxiliarythe output\n",
    "        a1 = F.softmax(self.aux_linear1(a1), dim = 1).unsqueeze(1)\n",
    "        a2 = F.softmax(self.aux_linear2(a2), dim = 1).unsqueeze(1)\n",
    "        #merging the vector to return the final auxiliary output\n",
    "        aux_output = torch.cat((a1, a2), 1)\n",
    "        \n",
    "        #computing the layers for the final output\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        output = F.softmax(self.fc5(x),dim=1)\n",
    "        return output, aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 2]), torch.Size([5, 2, 10]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checks\n",
    "model = C1L5()\n",
    "x = train_input[0:5]\n",
    "output, aux_output = model(x)\n",
    "output.shape, aux_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C2L2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #convolutions\n",
    "        self.conv1 = nn.Conv2d(2, 48, kernel_size=3,groups=2)\n",
    "        self.conv2 = nn.Conv2d(48, 240, kernel_size=3, groups = 2)\n",
    "        \n",
    "        #define the half lenght of the output (linearized) after the last convolution\n",
    "        self.h = int(2**2*240/2)\n",
    "        \n",
    "        #linear layers for the auxiliary losses\n",
    "        self.aux_linear1 = nn.Linear(self.h, 10)\n",
    "        self.aux_linear2 = nn.Linear(self.h, 10)\n",
    "        \n",
    "        #linear layers for the final output\n",
    "        self.fc1 = nn.Linear(2*self.h, 20)\n",
    "        self.fc2 = nn.Linear(20, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #computing the convolution\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = x.view(-1, 2*self.h)\n",
    "        \n",
    "        #computing the linear+softmax to make the auxiliary output\n",
    "        #deviding the tensor \n",
    "        a1 = x.narrow(1, 0,      self.h)\n",
    "        a2 = x.narrow(1, self.h, self.h)\n",
    "                \n",
    "        #computing auxiliarythe output\n",
    "        a1 = F.softmax(self.aux_linear1(a1), dim = 1).unsqueeze(1)\n",
    "        a2 = F.softmax(self.aux_linear2(a2), dim = 1).unsqueeze(1)\n",
    "        #merging the vector to return the final auxiliary output\n",
    "        aux_output = torch.cat((a1, a2), 1)\n",
    "        \n",
    "        #computing the layers for the final output\n",
    "        x = F.relu(self.fc1(x))\n",
    "        output = F.softmax(self.fc2(x), dim=1)\n",
    "        return output, aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 2]), torch.Size([5, 2, 10]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checks\n",
    "model = C2L2()\n",
    "x = train_input[0:5]\n",
    "output, aux_output = model(x)\n",
    "output.shape, aux_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C2L3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #convolutions\n",
    "        self.conv1 = nn.Conv2d(2, 32, kernel_size=3,groups=2)\n",
    "        self.conv2 = nn.Conv2d(32, 128, kernel_size=3,groups=2)\n",
    "        \n",
    "        #define the half lenght of the output (linearized) after the last convolution\n",
    "        self.h = int(2**2*128/2)\n",
    "        \n",
    "        #linear layers for the auxiliary losses\n",
    "        self.aux_linear1 = nn.Linear(self.h, 10)\n",
    "        self.aux_linear2 = nn.Linear(self.h, 10)\n",
    "        \n",
    "        #linear layers for the final output\n",
    "        self.fc1 = nn.Linear(2*self.h, 60)\n",
    "        self.fc2 = nn.Linear(60, 20)\n",
    "        self.fc3 = nn.Linear(20, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #computing the convolution\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = x.view(-1, 2*self.h)\n",
    "        \n",
    "        #computing the linear+softmax to make the auxiliary output\n",
    "        #deviding the tensor \n",
    "        a1 = x.narrow(1, 0,      self.h)\n",
    "        a2 = x.narrow(1, self.h, self.h)\n",
    "                \n",
    "        #computing auxiliarythe output\n",
    "        a1 = F.softmax(self.aux_linear1(a1), dim = 1).unsqueeze(1)\n",
    "        a2 = F.softmax(self.aux_linear2(a2), dim = 1).unsqueeze(1)\n",
    "        #merging the vector to return the final auxiliary output\n",
    "        aux_output = torch.cat((a1, a2), 1)\n",
    "        \n",
    "        #computing the layers for the final output\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        output = F.softmax(self.fc3(x), dim=1)\n",
    "        return output, aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 2]), torch.Size([5, 2, 10]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checks\n",
    "model = C2L3()\n",
    "x = train_input[0:5]\n",
    "output, aux_output = model(x)\n",
    "output.shape, aux_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C3L2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #convolutions\n",
    "        self.conv1 = nn.Conv2d(2, 22, kernel_size=3,groups=2)\n",
    "        self.conv2 = nn.Conv2d(22, 44, kernel_size=3,groups=2)\n",
    "        self.conv3 = nn.Conv2d(44, 88, kernel_size=3,groups=2)\n",
    "        \n",
    "        #define the half lenght of the output (linearized) after the last convolution\n",
    "        self.h = int(4**2*88/2)\n",
    "        \n",
    "        #linear layers for the auxiliary losses\n",
    "        self.aux_linear1 = nn.Linear(self.h, 10)\n",
    "        self.aux_linear2 = nn.Linear(self.h, 10)\n",
    "        \n",
    "        #linear layers for the final output\n",
    "        self.fc1 = nn.Linear(2*self.h, 20)\n",
    "        self.fc2 = nn.Linear(20, 2)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #computing the convolution\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x), kernel_size=2, stride=2))     \n",
    "        x = x.view(-1, 2*self.h)\n",
    "        \n",
    "        #computing the linear+softmax to make the auxiliary output\n",
    "        #deviding the tensor \n",
    "        a1 = x.narrow(1, 0,      self.h)\n",
    "        a2 = x.narrow(1, self.h, self.h)\n",
    "                \n",
    "        #computing auxiliarythe output\n",
    "        a1 = F.softmax(self.aux_linear1(a1), dim = 1).unsqueeze(1)\n",
    "        a2 = F.softmax(self.aux_linear2(a2), dim = 1).unsqueeze(1)\n",
    "        #merging the vector to return the final auxiliary output\n",
    "        aux_output = torch.cat((a1, a2), 1)\n",
    "        \n",
    "        #computing the layers for the final output\n",
    "        x = F.relu(self.fc1(x))\n",
    "        output = F.softmax(self.fc2(x), dim=1)\n",
    "        return output, aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 2]), torch.Size([5, 2, 10]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checks\n",
    "model = C3L2()\n",
    "x = train_input[0:5]\n",
    "output, aux_output = model(x)\n",
    "output.shape, aux_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C4L2_bis(nn.Module):#bis got switched, be careful\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #convolutions\n",
    "        self.conv1 = nn.Conv2d(2, 12, kernel_size=3,groups=2)\n",
    "        self.conv2 = nn.Conv2d(12, 24, kernel_size=3,groups=2)\n",
    "        self.conv3 = nn.Conv2d(24, 48, kernel_size=3,groups=2)\n",
    "        self.conv4 = nn.Conv2d(48, 96, kernel_size=3,groups=2)\n",
    "        \n",
    "        #define the half lenght of the output (linearized) after the last convolution\n",
    "        self.h = int(3**2*96/2)\n",
    "        \n",
    "        #linear layers for the auxiliary losses\n",
    "        self.aux_linear1 = nn.Linear(self.h, 10)\n",
    "        self.aux_linear2 = nn.Linear(self.h, 10)\n",
    "        \n",
    "        #linear layers for the final output\n",
    "        self.fc1 = nn.Linear(2*self.h, 20)\n",
    "        self.fc2 = nn.Linear(20, 2)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #computing the convolution\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv4(x), kernel_size=2, stride=2))\n",
    "        x = x.view(-1, 2*self.h)\n",
    "        \n",
    "        #computing the linear+softmax to make the auxiliary output\n",
    "        #deviding the tensor \n",
    "        a1 = x.narrow(1, 0,      self.h)\n",
    "        a2 = x.narrow(1, self.h, self.h)\n",
    "                \n",
    "        #computing auxiliarythe output\n",
    "        a1 = F.softmax(self.aux_linear1(a1), dim = 1).unsqueeze(1)\n",
    "        a2 = F.softmax(self.aux_linear2(a2), dim = 1).unsqueeze(1)\n",
    "        #merging the vector to return the final auxiliary output\n",
    "        aux_output = torch.cat((a1, a2), 1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        output = F.softmax(self.fc2(x), dim=1)\n",
    "        return output, aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 2]), torch.Size([5, 2, 10]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checks\n",
    "model = C4L2_bis()\n",
    "x = train_input[0:5]\n",
    "output, aux_output = model(x)\n",
    "output.shape, aux_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C4L2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #convolutions.\n",
    "        self.conv1 = nn.Conv2d(2, 16, kernel_size=3,groups=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3,groups=2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=2,groups=2)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=2,groups=2)\n",
    "        \n",
    "        #define the half lenght of the output (linearized) after the last convolution\n",
    "        self.h = int(3**2*128/2)\n",
    "        \n",
    "        #linear layers for the auxiliary losses\n",
    "        self.aux_linear1 = nn.Linear(self.h, 10)\n",
    "        self.aux_linear2 = nn.Linear(self.h, 10)\n",
    "        \n",
    "        #linear layers for the final output\n",
    "        self.fc1 = nn.Linear(2*self.h, 20)\n",
    "        self.fc2 = nn.Linear(20, 2)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #convolutional computations\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = x.view(-1, 2*self.h)\n",
    "        \n",
    "        #computing the linear+softmax to make the auxiliary output\n",
    "        #deviding the tensor \n",
    "        a1 = x.narrow(1, 0,      self.h)\n",
    "        a2 = x.narrow(1, self.h, self.h)\n",
    "        \n",
    "        #computing auxiliarythe output\n",
    "        a1 = F.softmax(self.aux_linear1(a1), dim = 1).unsqueeze(1)\n",
    "        a2 = F.softmax(self.aux_linear2(a2), dim = 1).unsqueeze(1)\n",
    "        #merging the vector to return the final auxiliary output\n",
    "        aux_output = torch.cat((a1, a2), 1)\n",
    "        \n",
    "        #computing the layers for the final output\n",
    "        x = F.relu(self.fc1(x))\n",
    "        output = F.softmax(self.fc2(x), dim=1)\n",
    "        return output, aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 2]), torch.Size([5, 2, 10]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checks\n",
    "model = C4L2()\n",
    "x = train_input[0:5]\n",
    "output, aux_output = model(x)\n",
    "output.shape, aux_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NetGroups3328Aux20' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-45c96050e63c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNetGroups3328Aux20\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'NetGroups3328Aux20' is not defined"
     ]
    }
   ],
   "source": [
    "m=NetGroups3328Aux20()\n",
    "print(n_params(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=NetGroups512_128Aux20()\n",
    "print(n_params(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=NetGroups320_160_80_40Aux20()\n",
    "print(n_params(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=NetGroupsDoubleConvAux20()\n",
    "print(n_params(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=NetGroups512_60DoubleConvAux20()\n",
    "print(n_params(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=NetGroups1408TripleConvAux20()\n",
    "print(n_params(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=NetGroups864QuadConvAux20()\n",
    "print(n_params(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=NetGroups1152QuadConvAux20_bis()\n",
    "print(n_params(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[C1L2,C2L2,C2L3,C3L2,C4L2]\n",
    "model_names=['C1L2','C2L2','C2L3','C3L2','C4L2']\n",
    "big_error_plot(models,model_names,n=10,nb_epochs=20,name='big_plot_aux=1.png',div=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Same as before with aux_factor=0.1\n",
    "models=[C1L2,C2L2,C2L3,C3L2,C4L2]\n",
    "model_names=['C1L2','C2L2','C2L3','C3L2','C4L2']\n",
    "big_error_plot(models,model_names,n=10,nb_epochs=20,aux_factor=0.1,name='big_plot_aux=01.png',div=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Same as before with aux_factor=0\n",
    "models=[C1L2,C2L2,C2L3,C3L2,C4L2]\n",
    "model_names=['C1L2','C2L2','C2L3','C3L2','C4L2']\n",
    "big_error_plot(models,model_names,n=10,nb_epochs=20,aux_factor=0,name='big_plot_aux=0.png',div=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tirocinio",
   "language": "python",
   "name": "tirocinio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
