{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "virtual-beast",
   "metadata": {
    "id": "thermal-humanity"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x206fe4a5f08>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cubic-bunch",
   "metadata": {
    "id": "found-annex"
   },
   "outputs": [],
   "source": [
    "class Parameter():\n",
    "    def __init__(self):\n",
    "        self.name = ''\n",
    "        self.data = None\n",
    "        self.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "duplicate-speaking",
   "metadata": {
    "id": "therapeutic-current"
   },
   "outputs": [],
   "source": [
    "class Module(object):\n",
    "    def forward (self, *input):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backward ( self , * gradwrtoutput ) :\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_parameters( self ) :\n",
    "        return []   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "worldwide-milwaukee",
   "metadata": {
    "id": "imperial-class",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Losses(object):        \n",
    "    def forward():\n",
    "        return NotImplementedError\n",
    "    def backward():\n",
    "        NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "after-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer(object):\n",
    "    def zero_grad(self):\n",
    "        for parameter in self.param : \n",
    "            parameter.grad = 0\n",
    "            \n",
    "    def step(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "egyptian-progress",
   "metadata": {
    "id": "comfortable-calgary"
   },
   "outputs": [],
   "source": [
    "class SGD(Optimizer):\n",
    "    # this is a SGD optimizer\n",
    "    def __init__(self,lr,max_iter, parameters) :  # should we add a \"tolerance_grad\" argument ? F: What do you mean with \"tolerance_grad\"\n",
    "        super().__init__()\n",
    "        self.eta = lr\n",
    "        self.maxStep = max_iter # maybe this shouldn't be put inside the module F: Agree\n",
    "        self.param = parameters\n",
    "        self.number_step = 0\n",
    "\n",
    "    def step(self): #batch de datapoint  --> confused : how can we do it stochastic ? ou alors on l'appelle step(batch)\n",
    "        # right now, eta is considered constant \n",
    "        #print(self.param[1].data)\n",
    "        #print('step')\n",
    "        if self.number_step <=self.maxStep:\n",
    "            for parameter in self.param :\n",
    "                #print(parameter)\n",
    "                #print(parameter.data[1])\n",
    "                parameter.data = parameter.data - self.eta * parameter.grad\n",
    "                #print(parameter.data[1])\n",
    "            self.number_step = self.number_step + 1\n",
    "            #print('after update',self.param[1].data)\n",
    "        return self.param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "incoming-dialogue",
   "metadata": {
    "id": "asian-evanescence"
   },
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    \n",
    "    def __init__(self, input_dim, out_dim, bias = True):\n",
    "        super().__init__()\n",
    "        std = 1/math.sqrt(input_dim)\n",
    "        self.weight = Parameter()\n",
    "        self.parameters = []\n",
    "        \n",
    "        self.weight.data = torch.rand(out_dim, input_dim)\n",
    "        self.weight.data = 2*std*self.weight.data - std\n",
    "        self.weight.name = 'weight'\n",
    "        self.parameters += [self.weight]\n",
    "        \n",
    "        self.with_bias = bias\n",
    "        if bias :\n",
    "            self.bias = Parameter()\n",
    "            self.bias.data = torch.rand(out_dim)\n",
    "            self.bias.data = 2*std*self.bias.data - std\n",
    "            self.bias.name = 'bias'\n",
    "            self.parameters +=[self.bias]\n",
    "            \n",
    "        self.x = None\n",
    "              \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return self.weight.data.mv(x) + self.bias.data\n",
    "        \n",
    "    def backward(self, prev_grad):\n",
    "        \n",
    "        prev_grad = prev_grad.view(-1, 1)\n",
    "        if self.x is None:\n",
    "            raise CallForwardFirst\n",
    "        \n",
    "        if self.weight.grad is None:\n",
    "            self.weight.grad = torch.zeros_like(self.weight.data)\n",
    "        \n",
    "        self.weight.grad += prev_grad.view(-1, 1)*self.x.view(1, -1)\n",
    "        \n",
    "        if self.with_bias:\n",
    "            if self.bias.grad is None:\n",
    "                self.bias.grad = torch.zeros_like(self.bias.data)\n",
    "            self.bias.grad += prev_grad.view(-1)\n",
    "        \n",
    "        next_grad = prev_grad.view(1, -1)@self.weight.data\n",
    "        next_grad = next_grad.view(-1, 1)\n",
    "        return next_grad\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        return self.parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "basic-encyclopedia",
   "metadata": {
    "id": "written-benjamin",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Tanh(Module):\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "    \n",
    "    def forward (self, x):\n",
    "        self.x = x\n",
    "        return torch.tanh(x)\n",
    "        \n",
    "    def backward ( self, prev_grad) :\n",
    "        if self.x is None:\n",
    "            raise CallForwardFirst\n",
    "            \n",
    "        def d(x):\n",
    "            return 4 * (x.exp() + x.mul(-1).exp()).pow(-2)\n",
    "        \n",
    "        return d(self.x)*prev_grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sunrise-murder",
   "metadata": {
    "id": "happy-review"
   },
   "outputs": [],
   "source": [
    "class MSE(Losses):\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "    def forward(self, x, t):\n",
    "        self.x = x\n",
    "        self.t = t\n",
    "        return (x - t).pow(2).mean()\n",
    "    \n",
    "    def backward(self):\n",
    "        if self.x == None or self.t == None:\n",
    "            raise CallForwardFirst\n",
    "        return 2 * (self.x - self.t)/len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "subjective-receipt",
   "metadata": {
    "id": "active-skirt"
   },
   "outputs": [],
   "source": [
    "class Sequential(object):\n",
    "    def __init__(self, modules):\n",
    "        super().__init__()\n",
    "        self.modules=modules\n",
    "        self.parameters = []\n",
    "        for m in self.modules:\n",
    "            param = m.get_parameters()\n",
    "            if param:\n",
    "                self.parameters += param\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for m in self.modules:\n",
    "            x=m.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, loss_grad):\n",
    "        x = loss_grad\n",
    "        for m in reversed(self.modules):\n",
    "            x = m.backward(x)\n",
    "            \n",
    "    def get_parameters(self):\n",
    "        return self.parameters\n",
    "\n",
    "    def set_parameters(self , params):\n",
    "        #print(self.parameters[1].data)\n",
    "        self.parameters = params\n",
    "        #print('after',self.parameters[1].data)\n",
    "        #for i in range (len(new_par)):\n",
    "         #   self.parameters[i] = params[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "medical-merchandise",
   "metadata": {
    "id": "legal-buying"
   },
   "outputs": [],
   "source": [
    "start_norm = []\n",
    "end_norm = []\n",
    "for i in range(20):\n",
    "    \n",
    "    x = torch.randn(9, requires_grad = False)\n",
    "    y = torch.randn(6,requires_grad = False)\n",
    "\n",
    "    linear = Linear(9, 6, True)\n",
    "    sigma = Tanh()\n",
    "    loss = MSE()\n",
    "\n",
    "    model = Sequential([\n",
    "        linear, \n",
    "        sigma\n",
    "    ])\n",
    "\n",
    "    loss = MSE()\n",
    "    optimizer = SGD(lr = 0.1,max_iter = 100, parameters = model.get_parameters())\n",
    "    (model.forward(x) - y).norm()\n",
    "    \n",
    "    start_norm += [(model.forward(x) - y).norm()]\n",
    "    for t in range(10**3):\n",
    "        # Forward pass: compute predicted y by passing x to the model.\n",
    "        y_pred = model.forward(x)\n",
    "\n",
    "        # Compute and print loss.\n",
    "        mse = loss.forward(y_pred, y)\n",
    "        #if t%99==0:\n",
    "        #    print(t, '   MSE loss = ' , mse.item())\n",
    "\n",
    "        #optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model\n",
    "        # parameters\n",
    "        model.backward(loss.backward())\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its\n",
    "        # parameters\n",
    "        new_par = optimizer.step()\n",
    "        #print(len(new_par))\n",
    "        model.set_parameters(new_par)\n",
    "        \n",
    "    end_norm += [(model.forward(x) - y).norm()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "boxed-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how does it compare with torch builtinfunctions ? \n",
    "start_norm_b = []\n",
    "end_norm_b = []\n",
    "for i in range(20):\n",
    "    x = torch.randn(9, requires_grad = False)\n",
    "    y = torch.randn(6,requires_grad = False)\n",
    "    torch.set_grad_enabled(True)\n",
    "\n",
    "    builtin_model = torch.nn.Sequential(\n",
    "              torch.nn.Linear(9,6),\n",
    "              torch.nn.Tanh()\n",
    "            )\n",
    "\n",
    "    loss = torch.nn.MSELoss()\n",
    "    optim = torch.optim.SGD(builtin_model.parameters(), momentum = 0., lr=0.1) #, momentum=None)\n",
    "    \n",
    "    \n",
    "    start_norm_b += [(builtin_model(x) - y).norm().item()]\n",
    "    for i in range(10**3):\n",
    "        optim.zero_grad()\n",
    "        l = loss(builtin_model(x), y)\n",
    "        l.backward()\n",
    "        optim.step()\n",
    "    end_norm_b+= [(builtin_model(x) - y).norm().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "circular-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "start_norm = np.array(start_norm)\n",
    "start_norm_b = np.array(start_norm_b)\n",
    "end_norm = np.array(end_norm)\n",
    "end_norm_b = np.array(end_norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "valuable-combine",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.5046544, 2.6501628160476685, 1.0949566, 0.7341336557516456)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_norm.mean(), start_norm_b.mean(), end_norm.mean(), end_norm_b.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "coastal-booking",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.73611104, 0.9338806749622279, 0.36315927, 0.6242520126243107)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_norm.std(), start_norm_b.std(), end_norm.std(), end_norm_b.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "respected-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comment: the std of the builtin function seems to be larger "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "matched-metabolism",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85009634, 2.163151  , 1.4973958 , 1.1858326 , 1.148578  ,\n",
       "       1.1113453 , 0.70269215, 0.67118526, 0.9788051 , 1.5970316 ,\n",
       "       1.1625462 , 1.2288423 , 1.2199734 , 0.8311082 , 1.3185073 ,\n",
       "       0.63410884, 0.7690381 , 0.77949744, 1.2229536 , 0.8264441 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acknowledged-scheme",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.84584141e-01, 2.38434839e+00, 2.49344112e-07, 1.46917319e+00,\n",
       "       5.40413260e-02, 4.61876392e-01, 9.27244961e-01, 2.35553205e-01,\n",
       "       1.66754472e+00, 8.56634021e-01, 3.02995950e-01, 1.07201123e+00,\n",
       "       1.48670539e-01, 9.99723002e-02, 9.83681560e-01, 6.59794569e-01,\n",
       "       1.07395566e+00, 8.52353990e-01, 2.65626311e-02, 1.22167408e+00])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_norm_b"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "modules+sequential_notokyet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tirocinio",
   "language": "python",
   "name": "tirocinio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
