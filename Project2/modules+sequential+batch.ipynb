{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "supported-helena",
   "metadata": {
    "id": "thermal-humanity"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "#torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "polar-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INTERESTING FACT: WHEN COMPUTING THE BATCH GRADIENT PYTORCH DOES NOT TAKE THE SUM OF THE GRADIENTA OF SINGLE DATA POINTS\n",
    "#BUT THE MEAN. I LEART AT THE EXPENSE OF ABOUT 1H LOL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "searching-tract",
   "metadata": {
    "id": "found-annex"
   },
   "outputs": [],
   "source": [
    "class Parameter():\n",
    "    def __init__(self):\n",
    "        self.name = ''\n",
    "        self.data = None\n",
    "        self.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unlimited-samoa",
   "metadata": {
    "id": "therapeutic-current"
   },
   "outputs": [],
   "source": [
    "class Module(object):\n",
    "    def forward (self, *input):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backward ( self , * gradwrtoutput ) :\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_parameters( self ) :\n",
    "        return []   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "driving-grade",
   "metadata": {
    "id": "imperial-class",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Losses(object):        \n",
    "    def forward():\n",
    "        return NotImplementedError\n",
    "    def backward():\n",
    "        NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "historic-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer(object):\n",
    "    def zero_grad(self):\n",
    "        for parameter in self.param : \n",
    "            parameter.grad = 0\n",
    "            \n",
    "    def step(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "egyptian-progress",
   "metadata": {
    "id": "comfortable-calgary"
   },
   "outputs": [],
   "source": [
    "class SGD(Optimizer):\n",
    "    # this is a SGD optimizer\n",
    "    def __init__(self,lr,max_iter, parameters) :  \n",
    "        super().__init__()\n",
    "        self.eta = lr\n",
    "        self.maxStep = max_iter \n",
    "        self.param = parameters\n",
    "        self.number_step = 0\n",
    "\n",
    "    def step(self): \n",
    "        if self.number_step <=self.maxStep:\n",
    "            for parameter in self.param :\n",
    "                parameter.data = parameter.data - self.eta * parameter.grad\n",
    "            self.number_step = self.number_step + 1\n",
    "        return self.param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "external-evolution",
   "metadata": {
    "id": "asian-evanescence"
   },
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    \n",
    "    def __init__(self, input_dim, out_dim, bias = True):\n",
    "        super().__init__()\n",
    "        std = 1/math.sqrt(input_dim)\n",
    "        self.weight = Parameter()\n",
    "        self.parameters = []\n",
    "        \n",
    "        self.weight.data = torch.rand(out_dim, input_dim)\n",
    "        self.weight.data = 2*std*self.weight.data - std\n",
    "        self.weight.name = 'weight'\n",
    "        self.parameters += [self.weight]\n",
    "        \n",
    "        self.with_bias = bias\n",
    "        if bias :\n",
    "            self.bias = Parameter()\n",
    "            self.bias.data = torch.rand(out_dim)\n",
    "            self.bias.data = 2*std*self.bias.data - std\n",
    "            self.bias.data = self.bias.data.unsqueeze(0)\n",
    "            self.bias.name = 'bias'\n",
    "            self.parameters +=[self.bias]\n",
    "            \n",
    "        self.x = None\n",
    "              \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.batch_size = x.shape[0]\n",
    "        return self.x.mm(self.weight.data.T) + self.bias.data\n",
    "        \n",
    "    def backward(self, prev_grad):\n",
    "        \n",
    "        prev_grad = prev_grad.view(self.batch_size, -1, 1)\n",
    "        print(prev_grad.shape)\n",
    "        if self.x is None:\n",
    "            raise CallForwardFirst\n",
    "        \n",
    "        if self.weight.grad is None:\n",
    "            self.weight.grad = torch.zeros_like(self.weight.data)\n",
    "        \n",
    "        grad_on_batch = prev_grad.view(self.batch_size, -1, 1)*self.x.view(self.batch_size, 1, -1)\n",
    "        self.weight.grad += grad_on_batch.mean(0)\n",
    "        \n",
    "        if self.with_bias:\n",
    "            if self.bias.grad is None:\n",
    "                self.bias.grad = torch.zeros_like(self.bias.data)\n",
    "            grad_on_batch = prev_grad.view(self.batch_size, -1)\n",
    "            self.bias.grad += grad_on_batch.mean(0)\n",
    "        \n",
    "        #if the output has dimension one, squeezing creates problems\n",
    "        if prev_grad.shape[1]>1:\n",
    "            prev_grad = prev_grad.squeeze()\n",
    "        next_grad = prev_grad@self.weight.data\n",
    "        return next_grad.squeeze()\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        return self.parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "secret-trader",
   "metadata": {
    "id": "written-benjamin",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Tanh(Module):\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "    \n",
    "    def forward (self, x):\n",
    "        self.x = x\n",
    "        return torch.tanh(x)\n",
    "        \n",
    "    def backward ( self, prev_grad) :\n",
    "        if self.x is None:\n",
    "            raise CallForwardFirst\n",
    "            \n",
    "        def d(x):\n",
    "            return 4 * (x.exp() + x.mul(-1).exp()).pow(-2)\n",
    "        \n",
    "        return d(self.x)*prev_grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "spiritual-orchestra",
   "metadata": {
    "id": "happy-review"
   },
   "outputs": [],
   "source": [
    "class MSE(Losses):\n",
    "    # Attention! Works well only when the vectors provided are of the form [batch_size, vector dimension]\n",
    "    # Otherwise it doesn know what dimesion to pick for the mean computation\n",
    "    #I'll fix this later\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "    def forward(self, x, t):\n",
    "        self.x = x\n",
    "        self.t = t\n",
    "        return (x - t).pow(2).mean()\n",
    "    \n",
    "    def backward(self):\n",
    "        if self.x == None or self.t == None:\n",
    "            raise CallForwardFirst\n",
    "        return 2 * (self.x - self.t)/self.x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "emerging-karma",
   "metadata": {
    "id": "active-skirt"
   },
   "outputs": [],
   "source": [
    "class Sequential(object):\n",
    "    def __init__(self, modules):\n",
    "        super().__init__()\n",
    "        self.modules=modules\n",
    "        self.parameters = []\n",
    "        for m in self.modules:\n",
    "            param = m.get_parameters()\n",
    "            if param:\n",
    "                self.parameters += param\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for m in self.modules:\n",
    "            x=m.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, loss_grad):\n",
    "        x = loss_grad\n",
    "        for m in reversed(self.modules):\n",
    "            x = m.backward(x)\n",
    "            \n",
    "    def get_parameters(self):\n",
    "        return self.parameters\n",
    "\n",
    "    def set_parameters(self , params):\n",
    "        self.parameters = params\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "technical-parameter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((tensor([[ 1.5183, -0.3843,  1.1086, -0.7034]]),),\n",
       " tensor([[ 1.5183, -0.3843,  1.1086, -0.7034]], grad_fn=<DivBackward0>),\n",
       " tensor([[ 6.0733, -1.5371,  4.4345, -2.8134]], grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that everything is working with loss backward\n",
    "x = torch.randn(1, 4, requires_grad = False)\n",
    "y = torch.randn(1, 4,requires_grad = False)\n",
    "\n",
    "a = x\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "\n",
    "loss_h = MSE()\n",
    "loss_b = torch.nn.MSELoss()\n",
    "\n",
    "l_h = loss_h.forward(x, y)\n",
    "l_b = loss_b(a, y)\n",
    "\n",
    "l_grad_b = torch.autograd.grad(l_b, a)\n",
    "l_grad_h = loss_h.backward()\n",
    "l_grad_b, l_grad_h, 2*(x-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "applied-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now check with linear as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "designing-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5, 9, requires_grad = False)\n",
    "y = torch.randn(5, 6,requires_grad = False)\n",
    "\n",
    "linear_h = Linear(9, 6)\n",
    "linear_b = torch.torch.nn.Linear(9, 6, True)\n",
    "linear_h.weight.data = linear_b.weight.data\n",
    "linear_h.bias.data = linear_b.bias.data\n",
    "\n",
    "output_b = linear_b(x)\n",
    "l_b = loss_b(output_b, y)\n",
    "l_b.backward(retain_graph = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dense-elements",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1647, -0.1573,  0.1060, -0.0011,  0.2459,  0.1486, -0.0902, -0.3420,\n",
       "         -0.0250],\n",
       "        [-0.1267,  0.3628,  0.0430,  0.2101, -0.3112, -0.2138,  0.0315,  0.4808,\n",
       "          0.4700],\n",
       "        [-0.0755,  0.0731,  0.0260,  0.2532, -0.1287, -0.0775, -0.0555,  0.2201,\n",
       "          0.2399],\n",
       "        [-0.1078,  0.2299,  0.2081,  0.0854, -0.1145,  0.0164,  0.1225,  0.1180,\n",
       "          0.2658],\n",
       "        [-0.0322,  0.2567,  0.4360,  0.0964, -0.1659,  0.0010,  0.0541,  0.3658,\n",
       "          0.4664]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_h = linear_h.forward(x)\n",
    "l_h = loss_h.forward(output_h, y)\n",
    "linear_h.backward(loss_h.backward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "looking-needle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0823,  0.4154,  0.2517, -0.1831,  0.2168,  0.4025],\n",
       "        [ 0.4309, -0.0210,  0.1993,  0.2315, -0.6915, -0.6663],\n",
       "        [ 0.0111,  0.2427,  0.1193,  0.1924, -0.4485, -0.4428],\n",
       "        [ 0.2455,  0.0623,  0.3447,  0.1548,  0.0201, -0.4344],\n",
       "        [ 0.6713,  0.3215,  0.2472,  0.5883, -0.0516, -0.6121]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_h.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "authorized-network",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2586,  0.0924,  0.1193, -0.0140,  0.0292,  0.1974, -0.0854,  0.0095,\n",
       "           0.1938],\n",
       "         [-0.0937, -0.0808,  0.1225, -0.0528,  0.1437, -0.2777,  0.0057, -0.0760,\n",
       "           0.0041],\n",
       "         [-0.2070, -0.0401,  0.0973,  0.0101,  0.1097, -0.1036,  0.0371,  0.0080,\n",
       "           0.0383],\n",
       "         [-0.1467,  0.1342,  0.1384, -0.0365, -0.0943,  0.1637, -0.0403,  0.0062,\n",
       "           0.1348],\n",
       "         [ 0.2227, -0.0567, -0.0387, -0.1095,  0.2686,  0.0691, -0.2601, -0.0740,\n",
       "          -0.0696],\n",
       "         [ 0.3406, -0.2119, -0.1840, -0.0495,  0.2834, -0.2320, -0.1338, -0.1068,\n",
       "          -0.1774]]),\n",
       " tensor([[-0.2586,  0.0924,  0.1193, -0.0140,  0.0292,  0.1974, -0.0854,  0.0095,\n",
       "           0.1938],\n",
       "         [-0.0937, -0.0808,  0.1225, -0.0528,  0.1437, -0.2777,  0.0057, -0.0760,\n",
       "           0.0041],\n",
       "         [-0.2070, -0.0401,  0.0973,  0.0101,  0.1097, -0.1036,  0.0371,  0.0080,\n",
       "           0.0383],\n",
       "         [-0.1467,  0.1342,  0.1384, -0.0365, -0.0943,  0.1637, -0.0403,  0.0062,\n",
       "           0.1348],\n",
       "         [ 0.2227, -0.0567, -0.0387, -0.1095,  0.2686,  0.0691, -0.2601, -0.0740,\n",
       "          -0.0696],\n",
       "         [ 0.3406, -0.2119, -0.1840, -0.0495,  0.2834, -0.2320, -0.1338, -0.1068,\n",
       "          -0.1774]]),\n",
       " tensor([[True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True]]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_b.weight.grad, linear_h.weight.grad,  abs(linear_b.weight.grad - linear_h.weight.grad) < 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "respiratory-validation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 0.,  2.,  4.,  6.,  8.],\n",
       "         [ 0.,  3.,  6.,  9., 12.],\n",
       "         [ 0.,  4.,  8., 12., 16.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 0.,  2.,  4.,  6.,  8.],\n",
       "         [ 0.,  3.,  6.,  9., 12.],\n",
       "         [ 0.,  4.,  8., 12., 16.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 0.,  2.,  4.,  6.,  8.],\n",
       "         [ 0.,  3.,  6.,  9., 12.],\n",
       "         [ 0.,  4.,  8., 12., 16.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 0.,  2.,  4.,  6.,  8.],\n",
       "         [ 0.,  3.,  6.,  9., 12.],\n",
       "         [ 0.,  4.,  8., 12., 16.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 0.,  2.,  4.,  6.,  8.],\n",
       "         [ 0.,  3.,  6.,  9., 12.],\n",
       "         [ 0.,  4.,  8., 12., 16.]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity check for whats going on when computing the gradient of the weights\n",
    "l = 1.*torch.ones(5, 5)*torch.arange(5).view(1, 5)\n",
    "m = 1.*torch.ones(5, 5)*torch.arange(5).view(1, 5)\n",
    "l.view(5, -1, 1)*m.view(5, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-montreal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "shared-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that builtin is doing the sum of the two on pytorch\n",
    "x = torch.randn(2, 9, requires_grad = False)\n",
    "y = torch.randn(2, 6,requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dress-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_b_1 = torch.torch.nn.Linear(9, 6, True)\n",
    "linear_b_1.weight.data = linear_b.weight.data\n",
    "linear_b_1.bias.data = linear_b.bias.data\n",
    "\n",
    "output_b_1 = linear_b_1(x[0])\n",
    "l_b_1 = loss_b(output_b_1, y[0])\n",
    "l_b_1.backward(retain_graph = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "pressing-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_b_2 = torch.torch.nn.Linear(9, 6, True)\n",
    "linear_b_2.weight.data = linear_b.weight.data\n",
    "linear_b_2.bias.data = linear_b.bias.data\n",
    "\n",
    "output_b_2 = linear_b_2(x[1])\n",
    "l_b_2 = loss_b(output_b_2, y[1])\n",
    "l_b_2.backward(retain_graph = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "opening-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_b_3 = torch.torch.nn.Linear(9, 6, True)\n",
    "linear_b_3.weight.data = linear_b.weight.data\n",
    "linear_b_3.bias.data = linear_b.bias.data\n",
    "\n",
    "output_b_3 = linear_b_3(x)\n",
    "l_b_3 = loss_b(output_b_3, y)\n",
    "l_b_3.backward(retain_graph = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "angry-beatles",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 1.9558e-08,  1.4901e-08,  3.7253e-09, -1.4901e-08, -3.7253e-09,\n",
       "          0.0000e+00,  5.9605e-08, -6.5193e-09, -7.4506e-09],\n",
       "        [ 7.4506e-09,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  1.3039e-08, -3.7253e-09,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00, -7.4506e-09,  0.0000e+00,  0.0000e+00,\n",
       "         -2.9802e-08, -1.1176e-08,  0.0000e+00, -7.4506e-09],\n",
       "        [ 0.0000e+00, -3.7253e-09,  1.8626e-09, -7.4506e-09, -1.8626e-09,\n",
       "         -3.7253e-09, -1.4901e-08,  0.0000e+00,  0.0000e+00],\n",
       "        [ 8.3819e-09, -1.4901e-08,  3.7253e-09, -2.2352e-08, -7.4506e-09,\n",
       "         -2.9802e-08, -1.4901e-08, -3.7253e-09,  7.4506e-09]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(linear_b_1.weight.grad + linear_b_2.weight.grad)/2 - linear_b_3.weight.grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "warming-switzerland",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 1.4901e-08, 0.0000e+00, 0.0000e+00, 3.7253e-09, 2.9802e-08])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(linear_b_1.bias.grad + linear_b_2.bias.grad)/2 -  linear_b_3.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "continuing-backup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial = torch.randn(3, 4, 2)\n",
    "len(trial.squeeze(2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "expensive-consumption",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 1])\n",
      "torch.Size([5, 6, 1])\n"
     ]
    }
   ],
   "source": [
    "#check using sequential \n",
    "x = torch.randn(5,9, requires_grad = False)\n",
    "y = torch.randn(5,1,requires_grad = False)\n",
    "\n",
    "#handmade sequential linear + relu \n",
    "linear1 = Linear(9, 6, True)\n",
    "linear2 = Linear(6, 1, True)\n",
    "sigma1 = Tanh()\n",
    "sigma2 = Tanh()\n",
    "loss = MSE()\n",
    "\n",
    "net = Sequential([\n",
    "    linear1, \n",
    "    sigma1,\n",
    "    linear2,\n",
    "    sigma2\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "output = net.forward(x)\n",
    "loss.forward(output, y)\n",
    "net.backward(loss.backward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "favorite-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intermediate = loss.backward()\n",
    "#intermediate = sigma2.backward(intermediate)\n",
    "#intermediate = linear2.backward(intermediate)\n",
    "#intermediate = sigma1.backward(intermediate)\n",
    "#intermediate = linear1.backward(intermediate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "virgin-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intermediate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "hidden-sunday",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1_b = torch.nn.Linear(9, 6)\n",
    "linear1_b.weight.data = linear1.weight.data\n",
    "linear1_b.bias.data = linear1.bias.data\n",
    "\n",
    "linear2_b = torch.nn.Linear(9, 6)\n",
    "linear2_b.weight.data = linear2.weight.data\n",
    "linear2_b.bias.data = linear2.bias.data\n",
    "\n",
    "\n",
    "\n",
    "model_b = torch.nn.Sequential(\n",
    "            linear1_b,\n",
    "            torch.nn.Tanh(),\n",
    "            linear2_b,\n",
    "            torch.nn.Tanh()\n",
    "        )\n",
    "output = model_b(x)\n",
    "l = torch.nn.MSELoss()(model_b(x), y)\n",
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "victorian-davis",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(abs(linear1.weight.grad - linear1_b.weight.grad) < 1e-7).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "floppy-prior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(abs(linear1.bias.grad - linear1_b.bias.grad)< 1e-7).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "likely-shopping",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(abs(linear2.weight.grad - linear2_b.weight.grad)< 1e-7).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "colonial-sample",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(abs(linear2.bias.grad - linear2_b.bias.grad)< 1e-6).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-explosion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tirocinio",
   "language": "python",
   "name": "tirocinio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
