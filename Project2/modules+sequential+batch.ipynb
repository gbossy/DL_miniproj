{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "supported-helena",
   "metadata": {
    "id": "thermal-humanity"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "#torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "subject-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INTERESTING FACT: WHEN COMPUTING THE BATCH GRADIENT PYTORCH DOES NOT TAKE THE SUM OF THE GRADIENTA OF SINGLE DATA POINTS\n",
    "#BUT THE MEAN. I LEART AT THE EXPENSE OF ABOUT 1H LOL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "searching-tract",
   "metadata": {
    "id": "found-annex"
   },
   "outputs": [],
   "source": [
    "class Parameter():\n",
    "    def __init__(self):\n",
    "        self.name = ''\n",
    "        self.data = None\n",
    "        self.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unlimited-samoa",
   "metadata": {
    "id": "therapeutic-current"
   },
   "outputs": [],
   "source": [
    "class Module(object):\n",
    "    def forward (self, *input):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backward ( self , * gradwrtoutput ) :\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_parameters( self ) :\n",
    "        return []   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "driving-grade",
   "metadata": {
    "id": "imperial-class",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Losses(object):        \n",
    "    def forward():\n",
    "        return NotImplementedError\n",
    "    def backward():\n",
    "        NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "historic-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer(object):\n",
    "    def zero_grad(self):\n",
    "        for parameter in self.param : \n",
    "            parameter.grad = 0\n",
    "            \n",
    "    def step(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "egyptian-progress",
   "metadata": {
    "id": "comfortable-calgary"
   },
   "outputs": [],
   "source": [
    "class SGD(Optimizer):\n",
    "    # this is a SGD optimizer\n",
    "    def __init__(self,lr,max_iter, parameters) :  \n",
    "        super().__init__()\n",
    "        self.eta = lr\n",
    "        self.maxStep = max_iter \n",
    "        self.param = parameters\n",
    "        self.number_step = 0\n",
    "\n",
    "    def step(self): \n",
    "        if self.number_step <=self.maxStep:\n",
    "            for parameter in self.param :\n",
    "                parameter.data = parameter.data - self.eta * parameter.grad\n",
    "            self.number_step = self.number_step + 1\n",
    "        return self.param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "external-evolution",
   "metadata": {
    "id": "asian-evanescence"
   },
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    \n",
    "    def __init__(self, input_dim, out_dim, bias = True):\n",
    "        super().__init__()\n",
    "        std = 1/math.sqrt(input_dim)\n",
    "        self.weight = Parameter()\n",
    "        self.parameters = []\n",
    "        \n",
    "        self.weight.data = torch.rand(out_dim, input_dim)\n",
    "        self.weight.data = 2*std*self.weight.data - std\n",
    "        self.weight.name = 'weight'\n",
    "        self.parameters += [self.weight]\n",
    "        \n",
    "        self.with_bias = bias\n",
    "        if bias :\n",
    "            self.bias = Parameter()\n",
    "            self.bias.data = torch.rand(out_dim)\n",
    "            self.bias.data = 2*std*self.bias.data - std\n",
    "            self.bias.data = self.bias.data.unsqueeze(0)\n",
    "            self.bias.name = 'bias'\n",
    "            self.parameters +=[self.bias]\n",
    "            \n",
    "        self.x = None\n",
    "              \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.batch_size = x.shape[0]\n",
    "        return self.x.mm(self.weight.data.T) + self.bias.data\n",
    "        \n",
    "    def backward(self, prev_grad):\n",
    "        \n",
    "        prev_grad = prev_grad.view(self.batch_size, -1, 1)\n",
    "        print(prev_grad.shape)\n",
    "        if self.x is None:\n",
    "            raise CallForwardFirst\n",
    "        \n",
    "        if self.weight.grad is None:\n",
    "            self.weight.grad = torch.zeros_like(self.weight.data)\n",
    "        \n",
    "        grad_on_batch = prev_grad.view(self.batch_size, -1, 1)*self.x.view(self.batch_size, 1, -1)\n",
    "        self.weight.grad += grad_on_batch.mean(0)\n",
    "        \n",
    "        if self.with_bias:\n",
    "            if self.bias.grad is None:\n",
    "                self.bias.grad = torch.zeros_like(self.bias.data)\n",
    "            grad_on_batch = prev_grad.view(self.batch_size, -1)\n",
    "            self.bias.grad += grad_on_batch.mean(0)\n",
    "        \n",
    "        #next_grad = prev_grad.view(1, -1)@self.weight.data\n",
    "        #next_grad = next_grad.view(-1, 1)\n",
    "        #return next_grad\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        return self.parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "secret-trader",
   "metadata": {
    "id": "written-benjamin",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Tanh(Module):\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "    \n",
    "    def forward (self, x):\n",
    "        self.x = x\n",
    "        return torch.tanh(x)\n",
    "        \n",
    "    def backward ( self, prev_grad) :\n",
    "        if self.x is None:\n",
    "            raise CallForwardFirst\n",
    "            \n",
    "        def d(x):\n",
    "            return 4 * (x.exp() + x.mul(-1).exp()).pow(-2)\n",
    "        \n",
    "        return d(self.x)*prev_grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "spiritual-orchestra",
   "metadata": {
    "id": "happy-review"
   },
   "outputs": [],
   "source": [
    "class MSE(Losses):\n",
    "    # Attention! Works well only when the vectors provided are of the form [batch_size, vector dimension]\n",
    "    # Otherwise it doesn know what dimesion to pick for the mean computation\n",
    "    #I'll fix this later\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "    def forward(self, x, t):\n",
    "        self.x = x\n",
    "        self.t = t\n",
    "        return (x - t).pow(2).mean()\n",
    "    \n",
    "    def backward(self):\n",
    "        if self.x == None or self.t == None:\n",
    "            raise CallForwardFirst\n",
    "        return 2 * (self.x - self.t)/self.x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "emerging-karma",
   "metadata": {
    "id": "active-skirt"
   },
   "outputs": [],
   "source": [
    "class Sequential(object):\n",
    "    def __init__(self, modules):\n",
    "        super().__init__()\n",
    "        self.modules=modules\n",
    "        self.parameters = []\n",
    "        for m in self.modules:\n",
    "            param = m.get_parameters()\n",
    "            if param:\n",
    "                self.parameters += param\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for m in self.modules:\n",
    "            x=m.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, loss_grad):\n",
    "        x = loss_grad\n",
    "        for m in reversed(self.modules):\n",
    "            x = m.backward(x)\n",
    "            \n",
    "    def get_parameters(self):\n",
    "        return self.parameters\n",
    "\n",
    "    def set_parameters(self , params):\n",
    "        self.parameters = params\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "governing-ideal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((tensor([[ 0.9481, -0.0926,  0.0346,  0.5703]]),),\n",
       " tensor([[ 0.9481, -0.0926,  0.0346,  0.5703]], grad_fn=<DivBackward0>),\n",
       " tensor([[ 3.7925, -0.3704,  0.1382,  2.2814]], grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that everything is working with loss backward\n",
    "x = torch.randn(1, 4, requires_grad = False)\n",
    "y = torch.randn(1, 4,requires_grad = False)\n",
    "\n",
    "a = x\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "\n",
    "loss_h = MSE()\n",
    "loss_b = torch.nn.MSELoss()\n",
    "\n",
    "l_h = loss_h.forward(x, y)\n",
    "l_b = loss_b(a, y)\n",
    "\n",
    "l_grad_b = torch.autograd.grad(l_b, a)\n",
    "l_grad_h = loss_h.backward()\n",
    "l_grad_b, l_grad_h, 2*(x-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "moved-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now check with linear as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "suited-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5, 9, requires_grad = False)\n",
    "y = torch.randn(5, 6,requires_grad = False)\n",
    "\n",
    "linear_h = Linear(9, 6)\n",
    "linear_b = torch.torch.nn.Linear(9, 6, True)\n",
    "linear_h.weight.data = linear_b.weight.data\n",
    "linear_h.bias.data = linear_b.bias.data\n",
    "\n",
    "output_b = linear_b(x)\n",
    "l_b = loss_b(output_b, y)\n",
    "l_b.backward(retain_graph = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "manufactured-fishing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6, 1])\n"
     ]
    }
   ],
   "source": [
    "output_h = linear_h.forward(x)\n",
    "l_h = loss_h.forward(output_h, y)\n",
    "linear_h.backward(loss_h.backward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "proprietary-thomas",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4649, -0.7647, -0.5509, -0.2238, -0.0072,  0.3812],\n",
       "        [-0.1325, -0.0872,  0.2394, -0.1855,  0.4789, -0.4686],\n",
       "        [-0.1473, -0.0965,  0.2050, -0.4820, -0.4123,  0.1531],\n",
       "        [-0.0361, -0.6278, -0.1105,  0.6435,  0.1467,  0.3227],\n",
       "        [ 0.2963, -0.1897,  0.0559, -0.1036, -0.0035,  0.0658]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_h.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "recent-viewer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0267,  0.1734,  0.0710,  0.1561,  0.0115,  0.0690,  0.0262, -0.1471,\n",
       "          -0.0240],\n",
       "         [ 0.1912,  0.0530, -0.1898, -0.2355,  0.1201, -0.1077,  0.0259,  0.0864,\n",
       "           0.0656],\n",
       "         [ 0.1123, -0.0955, -0.0488, -0.2785,  0.0059, -0.1236,  0.0239,  0.1398,\n",
       "           0.0299],\n",
       "         [ 0.0369, -0.1038,  0.0170,  0.1754,  0.1569, -0.0439, -0.1270, -0.0260,\n",
       "          -0.1318],\n",
       "         [-0.0330, -0.2764,  0.0410,  0.0624, -0.0586, -0.1115, -0.1599, -0.0314,\n",
       "          -0.0246],\n",
       "         [-0.0503,  0.2090,  0.0596,  0.1644,  0.0514,  0.1469,  0.0769, -0.0609,\n",
       "          -0.0533]]),\n",
       " tensor([[ 0.0267,  0.1734,  0.0710,  0.1561,  0.0115,  0.0690,  0.0262, -0.1471,\n",
       "          -0.0240],\n",
       "         [ 0.1912,  0.0530, -0.1898, -0.2355,  0.1201, -0.1077,  0.0259,  0.0864,\n",
       "           0.0656],\n",
       "         [ 0.1123, -0.0955, -0.0488, -0.2785,  0.0059, -0.1236,  0.0239,  0.1398,\n",
       "           0.0299],\n",
       "         [ 0.0369, -0.1038,  0.0170,  0.1754,  0.1569, -0.0439, -0.1270, -0.0260,\n",
       "          -0.1318],\n",
       "         [-0.0330, -0.2764,  0.0410,  0.0624, -0.0586, -0.1115, -0.1599, -0.0314,\n",
       "          -0.0246],\n",
       "         [-0.0503,  0.2090,  0.0596,  0.1644,  0.0514,  0.1469,  0.0769, -0.0609,\n",
       "          -0.0533]]),\n",
       " tensor([[True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_b.weight.grad, linear_h.weight.grad,  abs(linear_b.weight.grad - linear_h.weight.grad) < 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-folks",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sustained-holocaust",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 0.,  2.,  4.,  6.,  8.],\n",
       "         [ 0.,  3.,  6.,  9., 12.],\n",
       "         [ 0.,  4.,  8., 12., 16.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 0.,  2.,  4.,  6.,  8.],\n",
       "         [ 0.,  3.,  6.,  9., 12.],\n",
       "         [ 0.,  4.,  8., 12., 16.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 0.,  2.,  4.,  6.,  8.],\n",
       "         [ 0.,  3.,  6.,  9., 12.],\n",
       "         [ 0.,  4.,  8., 12., 16.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 0.,  2.,  4.,  6.,  8.],\n",
       "         [ 0.,  3.,  6.,  9., 12.],\n",
       "         [ 0.,  4.,  8., 12., 16.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 0.,  2.,  4.,  6.,  8.],\n",
       "         [ 0.,  3.,  6.,  9., 12.],\n",
       "         [ 0.,  4.,  8., 12., 16.]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity check for whats going on when computing the gradient of the weights\n",
    "l = 1.*torch.ones(5, 5)*torch.arange(5).view(1, 5)\n",
    "m = 1.*torch.ones(5, 5)*torch.arange(5).view(1, 5)\n",
    "l.view(5, -1, 1)*m.view(5, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-international",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "valid-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that builtin is doing the sum of the two on pytorch\n",
    "x = torch.randn(2, 9, requires_grad = False)\n",
    "y = torch.randn(2, 6,requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "portuguese-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_b_1 = torch.torch.nn.Linear(9, 6, True)\n",
    "linear_b_1.weight.data = linear_b.weight.data\n",
    "linear_b_1.bias.data = linear_b.bias.data\n",
    "\n",
    "output_b_1 = linear_b_1(x[0])\n",
    "l_b_1 = loss_b(output_b_1, y[0])\n",
    "l_b_1.backward(retain_graph = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "colored-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_b_2 = torch.torch.nn.Linear(9, 6, True)\n",
    "linear_b_2.weight.data = linear_b.weight.data\n",
    "linear_b_2.bias.data = linear_b.bias.data\n",
    "\n",
    "output_b_2 = linear_b_2(x[1])\n",
    "l_b_2 = loss_b(output_b_2, y[1])\n",
    "l_b_2.backward(retain_graph = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "exciting-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_b_3 = torch.torch.nn.Linear(9, 6, True)\n",
    "linear_b_3.weight.data = linear_b.weight.data\n",
    "linear_b_3.bias.data = linear_b.bias.data\n",
    "\n",
    "output_b_3 = linear_b_3(x)\n",
    "l_b_3 = loss_b(output_b_3, y)\n",
    "l_b_3.backward(retain_graph = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fatty-keeping",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1492, -0.0264,  0.2193,  0.0035,  0.0215,  0.0057,  0.1597, -0.1664,\n",
       "          -0.0273],\n",
       "         [-0.1171,  0.0207, -0.1721, -0.0027, -0.0169, -0.0045, -0.1254,  0.1306,\n",
       "           0.0214],\n",
       "         [ 0.5576, -0.0987,  0.8196,  0.0129,  0.0804,  0.0214,  0.5969, -0.6219,\n",
       "          -0.1021],\n",
       "         [-0.9310,  0.1648, -1.3685, -0.0216, -0.1343, -0.0358, -0.9967,  1.0385,\n",
       "           0.1705],\n",
       "         [ 0.2192, -0.0388,  0.3222,  0.0051,  0.0316,  0.0084,  0.2347, -0.2445,\n",
       "          -0.0401],\n",
       "         [ 0.3500, -0.0620,  0.5144,  0.0081,  0.0505,  0.0135,  0.3747, -0.3904,\n",
       "          -0.0641]]),\n",
       " tensor([[-0.0409, -0.0569,  0.0590, -0.0771, -0.0742, -0.0524, -0.0918, -0.0081,\n",
       "           0.0923],\n",
       "         [-0.1657, -0.2305,  0.2394, -0.3126, -0.3007, -0.2123, -0.3722, -0.0327,\n",
       "           0.3743],\n",
       "         [-0.0480, -0.0668,  0.0693, -0.0905, -0.0871, -0.0615, -0.1078, -0.0095,\n",
       "           0.1084],\n",
       "         [ 0.0880,  0.1225, -0.1271,  0.1660,  0.1597,  0.1128,  0.1977,  0.0173,\n",
       "          -0.1988],\n",
       "         [-0.0492, -0.0685,  0.0711, -0.0929, -0.0894, -0.0631, -0.1106, -0.0097,\n",
       "           0.1112],\n",
       "         [ 0.0340,  0.0473, -0.0491,  0.0641,  0.0617,  0.0435,  0.0763,  0.0067,\n",
       "          -0.0768]]),\n",
       " tensor([[ 0.1083, -0.0833,  0.2783, -0.0736, -0.0526, -0.0466,  0.0679, -0.1745,\n",
       "           0.0650],\n",
       "         [-0.2828, -0.2098,  0.0672, -0.3153, -0.3176, -0.2168, -0.4975,  0.0980,\n",
       "           0.3958],\n",
       "         [ 0.5096, -0.1655,  0.8889, -0.0776, -0.0067, -0.0400,  0.4891, -0.6314,\n",
       "           0.0063],\n",
       "         [-0.8430,  0.2873, -1.4956,  0.1444,  0.0254,  0.0770, -0.7990,  1.0559,\n",
       "          -0.0283],\n",
       "         [ 0.1700, -0.1073,  0.3933, -0.0878, -0.0577, -0.0547,  0.1241, -0.2542,\n",
       "           0.0711],\n",
       "         [ 0.3840, -0.0147,  0.4653,  0.0722,  0.1122,  0.0570,  0.4510, -0.3837,\n",
       "          -0.1409]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_b_1.weight.grad, linear_b_2.weight.grad, linear_b_1.weight.grad + linear_b_2.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "protecting-clear",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 1.4901e-08, 0.0000e+00, 0.0000e+00, 1.4901e-08, 1.4901e-08])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(linear_b_1.bias.grad + linear_b_2.bias.grad)/2 -  linear_b_3.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-works",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "veterinary-cooking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6, 1])\n"
     ]
    }
   ],
   "source": [
    "#check using sequential \n",
    "x = torch.randn(5,9, requires_grad = False)\n",
    "y = torch.randn(5,6,requires_grad = False)\n",
    "\n",
    "#handmade sequential linear + relu \n",
    "linear = Linear(9, 6, True)\n",
    "sigma = Tanh()\n",
    "loss = MSE()\n",
    "\n",
    "net = Sequential([\n",
    "    linear, \n",
    "    sigma\n",
    "])\n",
    "\n",
    "output = net.forward(x)\n",
    "loss.forward(output, y)\n",
    "net.backward(loss.backward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "forced-teens",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4537, 0.5416]]), tensor([0.4537, 0.5416]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(1, 2)\n",
    "a, a.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "congressional-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_linear = torch.nn.Linear(9, 6, True)\n",
    "b_linear.weight.data = linear.weight.data\n",
    "b_linear.bias.data = linear.bias.data\n",
    "l = torch.nn.MSELoss()(torch.tanh(b_linear(x)), y)\n",
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dependent-bidder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0343,  0.0278, -0.2554,  0.2128, -0.0976,  0.0224, -0.1785,  0.0978,\n",
       "           0.0864],\n",
       "         [ 0.1753,  0.1938, -0.0117, -0.2619,  0.0627, -0.1679,  0.0494, -0.2939,\n",
       "           0.0582],\n",
       "         [ 0.2058,  0.0386,  0.1591,  0.1545, -0.0618, -0.0441,  0.1622,  0.0811,\n",
       "          -0.1307],\n",
       "         [ 0.2749,  0.1305,  0.1839,  0.0413,  0.1018, -0.1290,  0.1823,  0.1821,\n",
       "          -0.1829],\n",
       "         [ 0.0836,  0.0426,  0.1275, -0.2277,  0.1930, -0.0714,  0.1088,  0.0109,\n",
       "          -0.0579],\n",
       "         [ 0.2070,  0.0897,  0.1698, -0.1467,  0.1005, -0.1085,  0.1765, -0.0551,\n",
       "          -0.0836]]),\n",
       " tensor([[-0.0343,  0.0278, -0.2554,  0.2128, -0.0976,  0.0224, -0.1785,  0.0978,\n",
       "           0.0864],\n",
       "         [ 0.1753,  0.1938, -0.0117, -0.2619,  0.0627, -0.1679,  0.0494, -0.2939,\n",
       "           0.0582],\n",
       "         [ 0.2058,  0.0386,  0.1591,  0.1545, -0.0618, -0.0441,  0.1622,  0.0811,\n",
       "          -0.1307],\n",
       "         [ 0.2749,  0.1305,  0.1839,  0.0413,  0.1018, -0.1290,  0.1823,  0.1821,\n",
       "          -0.1829],\n",
       "         [ 0.0836,  0.0426,  0.1275, -0.2277,  0.1930, -0.0714,  0.1088,  0.0109,\n",
       "          -0.0579],\n",
       "         [ 0.2070,  0.0897,  0.1698, -0.1467,  0.1005, -0.1085,  0.1765, -0.0551,\n",
       "          -0.0836]]),\n",
       " tensor(5.9605e-08))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_linear.weight.grad, linear.weight.grad,  abs(b_linear.weight.grad - linear.weight.grad).max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "allied-leave",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0390, -0.0516, -0.1697, -0.0048,  0.0924, -0.0655]]),\n",
       " tensor([[ 0.0390, -0.0516, -0.1697, -0.0048,  0.0924, -0.0655]]),\n",
       " tensor(1.8626e-08))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_linear.bias.grad, linear.bias.grad,  abs(b_linear.bias.grad - linear.bias.grad).max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tirocinio",
   "language": "python",
   "name": "tirocinio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
