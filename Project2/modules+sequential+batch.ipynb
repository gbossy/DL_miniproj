{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "supported-helena",
   "metadata": {
    "id": "thermal-humanity"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "#torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "identified-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INTERESTING FACT: WHEN COMPUTING THE BATCH GRADIENT PYTORCH DOES NOT TAKE THE SUM OF THE GRADIENTA OF SINGLE DATA POINTS\n",
    "#BUT THE MEAN. I LEART AT THE EXPENSE OF ABOUT 1H LOL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "searching-tract",
   "metadata": {
    "id": "found-annex"
   },
   "outputs": [],
   "source": [
    "class Parameter():\n",
    "    def __init__(self):\n",
    "        self.name = ''\n",
    "        self.data = None\n",
    "        self.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unlimited-samoa",
   "metadata": {
    "id": "therapeutic-current"
   },
   "outputs": [],
   "source": [
    "class Module(object):\n",
    "    def forward (self, *input):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backward ( self , * gradwrtoutput ) :\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_parameters( self ) :\n",
    "        return []   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "driving-grade",
   "metadata": {
    "id": "imperial-class",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Losses(object):        \n",
    "    def forward():\n",
    "        return NotImplementedError\n",
    "    def backward():\n",
    "        NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "historic-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer(object):\n",
    "    def zero_grad(self):\n",
    "        for parameter in self.param : \n",
    "            parameter.grad = 0\n",
    "            \n",
    "    def step(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "egyptian-progress",
   "metadata": {
    "id": "comfortable-calgary"
   },
   "outputs": [],
   "source": [
    "class SGD(Optimizer):\n",
    "    # this is a SGD optimizer\n",
    "    def __init__(self,lr,max_iter, parameters) :  \n",
    "        super().__init__()\n",
    "        self.eta = lr\n",
    "        self.maxStep = max_iter \n",
    "        self.param = parameters\n",
    "        self.number_step = 0\n",
    "\n",
    "    def step(self): \n",
    "        if self.number_step <=self.maxStep:\n",
    "            for parameter in self.param :\n",
    "                parameter.data = parameter.data - self.eta * parameter.grad\n",
    "            self.number_step = self.number_step + 1\n",
    "        return self.param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "external-evolution",
   "metadata": {
    "id": "asian-evanescence"
   },
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    \n",
    "    def __init__(self, input_dim, out_dim, bias = True):\n",
    "        super().__init__()\n",
    "        std = 1/math.sqrt(input_dim)\n",
    "        self.weight = Parameter()\n",
    "        self.parameters = []\n",
    "        \n",
    "        self.weight.data = torch.rand(out_dim, input_dim)\n",
    "        self.weight.data = 2*std*self.weight.data - std\n",
    "        self.weight.name = 'weight'\n",
    "        self.parameters += [self.weight]\n",
    "        \n",
    "        self.with_bias = bias\n",
    "        if bias :\n",
    "            self.bias = Parameter()\n",
    "            self.bias.data = torch.rand(out_dim)\n",
    "            self.bias.data = 2*std*self.bias.data - std\n",
    "            self.bias.data = self.bias.data.unsqueeze(0)\n",
    "            self.bias.name = 'bias'\n",
    "            self.parameters +=[self.bias]\n",
    "            \n",
    "        self.x = None\n",
    "              \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.batch_size = x.shape[0]\n",
    "        return self.x.mm(self.weight.data.T) + self.bias.data\n",
    "        \n",
    "    def backward(self, prev_grad):\n",
    "        \n",
    "        prev_grad = prev_grad.view(self.batch_size, -1, 1)\n",
    "        print(prev_grad.shape)\n",
    "        if self.x is None:\n",
    "            raise CallForwardFirst\n",
    "        \n",
    "        if self.weight.grad is None:\n",
    "            self.weight.grad = torch.zeros_like(self.weight.data)\n",
    "        \n",
    "        grad_on_batch = prev_grad.view(self.batch_size, -1, 1)*self.x.view(self.batch_size, 1, -1)\n",
    "        self.weight.grad += grad_on_batch.mean(0)\n",
    "        \n",
    "        if self.with_bias:\n",
    "            if self.bias.grad is None:\n",
    "                self.bias.grad = torch.zeros_like(self.bias.data)\n",
    "            grad_on_batch = prev_grad.view(self.batch_size, -1)\n",
    "            self.bias.grad += grad_on_batch.mean(0)\n",
    "        \n",
    "        next_grad = prev_grad.squeeze()@self.weight.data\n",
    "        return next_grad.squeeze()\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        return self.parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ruled-batch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11],\n",
       "         [12, 13, 14],\n",
       "         [15, 16, 17]]),\n",
       " tensor([[ 0,  3,  6,  9, 12, 15],\n",
       "         [ 1,  4,  7, 10, 13, 16],\n",
       "         [ 2,  5,  8, 11, 14, 17]]),\n",
       " tensor([[ 0,  1,  2,  3,  4,  5],\n",
       "         [ 6,  7,  8,  9, 10, 11],\n",
       "         [12, 13, 14, 15, 16, 17]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(18).view(6, 3)\n",
    "a, a.T, a.view(3, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "secret-trader",
   "metadata": {
    "id": "written-benjamin",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Tanh(Module):\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "    \n",
    "    def forward (self, x):\n",
    "        self.x = x\n",
    "        return torch.tanh(x)\n",
    "        \n",
    "    def backward ( self, prev_grad) :\n",
    "        if self.x is None:\n",
    "            raise CallForwardFirst\n",
    "            \n",
    "        def d(x):\n",
    "            return 4 * (x.exp() + x.mul(-1).exp()).pow(-2)\n",
    "        \n",
    "        return d(self.x)*prev_grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "spiritual-orchestra",
   "metadata": {
    "id": "happy-review"
   },
   "outputs": [],
   "source": [
    "class MSE(Losses):\n",
    "    # Attention! Works well only when the vectors provided are of the form [batch_size, vector dimension]\n",
    "    # Otherwise it doesn know what dimesion to pick for the mean computation\n",
    "    #I'll fix this later\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "    def forward(self, x, t):\n",
    "        self.x = x\n",
    "        self.t = t\n",
    "        return (x - t).pow(2).mean()\n",
    "    \n",
    "    def backward(self):\n",
    "        if self.x == None or self.t == None:\n",
    "            raise CallForwardFirst\n",
    "        return 2 * (self.x - self.t)/self.x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "emerging-karma",
   "metadata": {
    "id": "active-skirt"
   },
   "outputs": [],
   "source": [
    "class Sequential(object):\n",
    "    def __init__(self, modules):\n",
    "        super().__init__()\n",
    "        self.modules=modules\n",
    "        self.parameters = []\n",
    "        for m in self.modules:\n",
    "            param = m.get_parameters()\n",
    "            if param:\n",
    "                self.parameters += param\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for m in self.modules:\n",
    "            x=m.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, loss_grad):\n",
    "        x = loss_grad\n",
    "        for m in reversed(self.modules):\n",
    "            x = m.backward(x)\n",
    "            \n",
    "    def get_parameters(self):\n",
    "        return self.parameters\n",
    "\n",
    "    def set_parameters(self , params):\n",
    "        self.parameters = params\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "friendly-omega",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((tensor([[-0.7974,  0.3765, -0.2241,  0.6983]]),),\n",
       " tensor([[-0.7974,  0.3765, -0.2241,  0.6983]], grad_fn=<DivBackward0>),\n",
       " tensor([[-3.1898,  1.5059, -0.8964,  2.7933]], grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that everything is working with loss backward\n",
    "x = torch.randn(1, 4, requires_grad = False)\n",
    "y = torch.randn(1, 4,requires_grad = False)\n",
    "\n",
    "a = x\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "\n",
    "loss_h = MSE()\n",
    "loss_b = torch.nn.MSELoss()\n",
    "\n",
    "l_h = loss_h.forward(x, y)\n",
    "l_b = loss_b(a, y)\n",
    "\n",
    "l_grad_b = torch.autograd.grad(l_b, a)\n",
    "l_grad_h = loss_h.backward()\n",
    "l_grad_b, l_grad_h, 2*(x-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "presidential-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now check with linear as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "spare-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5, 9, requires_grad = False)\n",
    "y = torch.randn(5, 6,requires_grad = False)\n",
    "\n",
    "linear_h = Linear(9, 6)\n",
    "linear_b = torch.torch.nn.Linear(9, 6, True)\n",
    "linear_h.weight.data = linear_b.weight.data\n",
    "linear_h.bias.data = linear_b.bias.data\n",
    "\n",
    "output_b = linear_b(x)\n",
    "l_b = loss_b(output_b, y)\n",
    "l_b.backward(retain_graph = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "detailed-cyprus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0693, -0.0367, -0.0594, -0.1170, -0.0534, -0.0876, -0.0284, -0.0008,\n",
       "          0.1028],\n",
       "        [ 0.0731,  0.3287, -0.2622,  0.2584, -0.0312, -0.0327, -0.0440,  0.1288,\n",
       "          0.0102],\n",
       "        [-0.0519,  0.0316, -0.1405,  0.0894,  0.3071, -0.3966,  0.2702, -0.0963,\n",
       "         -0.0354],\n",
       "        [ 0.2142, -0.1043,  0.0731,  0.1528, -0.0365,  0.0779, -0.0569, -0.0441,\n",
       "         -0.0818],\n",
       "        [-0.1484,  0.3120, -0.0754, -0.0864,  0.1935,  0.0080, -0.0174, -0.0761,\n",
       "         -0.1320]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_h = linear_h.forward(x)\n",
    "l_h = loss_h.forward(output_h, y)\n",
    "linear_h.backward(loss_h.backward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "strange-sense",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1100,  0.1142,  0.4872, -0.0994,  0.0351, -0.3508],\n",
       "        [ 0.3909, -0.7089,  0.1504, -0.3205, -0.1875, -0.2590],\n",
       "        [ 0.6420,  0.4862,  0.1666, -0.2090,  0.0807, -0.1244],\n",
       "        [-0.1036, -0.0837, -0.8094, -0.0772, -0.0430,  0.2582],\n",
       "        [ 0.2278, -0.1420,  0.2988, -0.2273, -0.3797,  0.3321]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_h.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "burning-worry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0924,  0.2807, -0.2322,  0.1941,  0.1369,  0.2125,  0.0415,  0.0295,\n",
       "           0.2046],\n",
       "         [-0.4066, -0.2232,  0.0105, -0.1673, -0.1210, -0.1121,  0.2864,  0.0405,\n",
       "           0.3036],\n",
       "         [-0.0274,  0.1209, -0.0956, -0.1146, -0.4105, -0.2380, -0.0418, -0.0054,\n",
       "           0.3704],\n",
       "         [-0.1045, -0.1392,  0.0911, -0.0952, -0.1580, -0.1141,  0.0744,  0.0378,\n",
       "          -0.0388],\n",
       "         [-0.0825, -0.0530, -0.0169, -0.0942, -0.1769, -0.1412,  0.1219,  0.0837,\n",
       "           0.1172],\n",
       "         [-0.1303, -0.1307,  0.1256,  0.0923,  0.2986,  0.2332, -0.0079, -0.0899,\n",
       "          -0.2476]]),\n",
       " tensor([[-0.0924,  0.2807, -0.2322,  0.1941,  0.1369,  0.2125,  0.0415,  0.0295,\n",
       "           0.2046],\n",
       "         [-0.4066, -0.2232,  0.0105, -0.1673, -0.1210, -0.1121,  0.2864,  0.0405,\n",
       "           0.3036],\n",
       "         [-0.0274,  0.1209, -0.0956, -0.1146, -0.4105, -0.2380, -0.0418, -0.0054,\n",
       "           0.3704],\n",
       "         [-0.1045, -0.1392,  0.0911, -0.0952, -0.1580, -0.1141,  0.0744,  0.0378,\n",
       "          -0.0388],\n",
       "         [-0.0825, -0.0530, -0.0169, -0.0942, -0.1769, -0.1412,  0.1219,  0.0837,\n",
       "           0.1172],\n",
       "         [-0.1303, -0.1307,  0.1256,  0.0923,  0.2986,  0.2332, -0.0079, -0.0899,\n",
       "          -0.2476]]),\n",
       " tensor([[True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_b.weight.grad, linear_h.weight.grad,  abs(linear_b.weight.grad - linear_h.weight.grad) < 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-bonus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "together-nashville",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 0.,  2.,  4.,  6.,  8.],\n",
       "         [ 0.,  3.,  6.,  9., 12.],\n",
       "         [ 0.,  4.,  8., 12., 16.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 0.,  2.,  4.,  6.,  8.],\n",
       "         [ 0.,  3.,  6.,  9., 12.],\n",
       "         [ 0.,  4.,  8., 12., 16.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 0.,  2.,  4.,  6.,  8.],\n",
       "         [ 0.,  3.,  6.,  9., 12.],\n",
       "         [ 0.,  4.,  8., 12., 16.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 0.,  2.,  4.,  6.,  8.],\n",
       "         [ 0.,  3.,  6.,  9., 12.],\n",
       "         [ 0.,  4.,  8., 12., 16.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 0.,  2.,  4.,  6.,  8.],\n",
       "         [ 0.,  3.,  6.,  9., 12.],\n",
       "         [ 0.,  4.,  8., 12., 16.]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity check for whats going on when computing the gradient of the weights\n",
    "l = 1.*torch.ones(5, 5)*torch.arange(5).view(1, 5)\n",
    "m = 1.*torch.ones(5, 5)*torch.arange(5).view(1, 5)\n",
    "l.view(5, -1, 1)*m.view(5, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-porter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "undefined-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that builtin is doing the sum of the two on pytorch\n",
    "x = torch.randn(2, 9, requires_grad = False)\n",
    "y = torch.randn(2, 6,requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bearing-parameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_b_1 = torch.torch.nn.Linear(9, 6, True)\n",
    "linear_b_1.weight.data = linear_b.weight.data\n",
    "linear_b_1.bias.data = linear_b.bias.data\n",
    "\n",
    "output_b_1 = linear_b_1(x[0])\n",
    "l_b_1 = loss_b(output_b_1, y[0])\n",
    "l_b_1.backward(retain_graph = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "improved-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_b_2 = torch.torch.nn.Linear(9, 6, True)\n",
    "linear_b_2.weight.data = linear_b.weight.data\n",
    "linear_b_2.bias.data = linear_b.bias.data\n",
    "\n",
    "output_b_2 = linear_b_2(x[1])\n",
    "l_b_2 = loss_b(output_b_2, y[1])\n",
    "l_b_2.backward(retain_graph = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "expected-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_b_3 = torch.torch.nn.Linear(9, 6, True)\n",
    "linear_b_3.weight.data = linear_b.weight.data\n",
    "linear_b_3.bias.data = linear_b.bias.data\n",
    "\n",
    "output_b_3 = linear_b_3(x)\n",
    "l_b_3 = loss_b(output_b_3, y)\n",
    "l_b_3.backward(retain_graph = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "general-parts",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00, -2.9802e-08,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  5.9605e-08,  0.0000e+00],\n",
       "        [ 7.4506e-09,  0.0000e+00,  0.0000e+00, -2.9802e-08,  0.0000e+00,\n",
       "          3.7253e-09,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 2.9802e-08,  0.0000e+00,  1.4901e-08,  1.4901e-08,  4.4703e-08,\n",
       "         -4.4703e-08,  2.2352e-08,  0.0000e+00,  2.9802e-08],\n",
       "        [ 0.0000e+00,  1.4901e-08, -7.4506e-09,  2.2352e-08, -2.9802e-08,\n",
       "          0.0000e+00, -1.1176e-08,  4.4703e-08,  1.4901e-08],\n",
       "        [ 0.0000e+00, -1.4901e-08,  0.0000e+00,  0.0000e+00,  3.7253e-09,\n",
       "          0.0000e+00, -1.8626e-09,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  2.9802e-08,  5.9605e-08,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(linear_b_1.weight.grad + linear_b_2.weight.grad)/2 - linear_b_3.weight.grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "orange-genius",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000e+00,  0.0000e+00,  2.9802e-08, -2.2352e-08,  0.0000e+00,\n",
       "         0.0000e+00])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(linear_b_1.bias.grad + linear_b_2.bias.grad)/2 -  linear_b_3.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-porcelain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "athletic-dietary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 7, 1])\n",
      "torch.Size([5, 6, 1])\n"
     ]
    }
   ],
   "source": [
    "#check using sequential \n",
    "x = torch.randn(5,9, requires_grad = False)\n",
    "y = torch.randn(5,7,requires_grad = False)\n",
    "\n",
    "#handmade sequential linear + relu \n",
    "linear1 = Linear(9, 6, True)\n",
    "linear2 = Linear(6, 7, True)\n",
    "sigma1 = Tanh()\n",
    "sigma2 = Tanh()\n",
    "loss = MSE()\n",
    "\n",
    "net = Sequential([\n",
    "    linear1, \n",
    "    sigma1,\n",
    "    linear2,\n",
    "    sigma2\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "output = net.forward(x)\n",
    "loss.forward(output, y)\n",
    "net.backward(loss.backward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sporting-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intermediate = loss.backward()\n",
    "#intermediate = sigma2.backward(intermediate)\n",
    "#intermediate = linear2.backward(intermediate)\n",
    "#intermediate = sigma1.backward(intermediate)\n",
    "#intermediate = linear1.backward(intermediate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "electronic-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intermediate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "automated-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1_b = torch.nn.Linear(9, 6)\n",
    "linear1_b.weight.data = linear1.weight.data\n",
    "linear1_b.bias.data = linear1.bias.data\n",
    "\n",
    "linear2_b = torch.nn.Linear(9, 6)\n",
    "linear2_b.weight.data = linear2.weight.data\n",
    "linear2_b.bias.data = linear2.bias.data\n",
    "\n",
    "\n",
    "\n",
    "model_b = torch.nn.Sequential(\n",
    "            linear1_b,\n",
    "            torch.nn.Tanh(),\n",
    "            linear2_b,\n",
    "            torch.nn.Tanh()\n",
    "        )\n",
    "output = model_b(x)\n",
    "l = torch.nn.MSELoss()(model_b(x), y)\n",
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fifty-belly",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(abs(linear1.weight.grad - linear1_b.weight.grad) < 1e-7).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "passive-acting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(abs(linear1.bias.grad - linear1_b.bias.grad)< 1e-7).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "substantial-environment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(abs(linear2.weight.grad - linear2_b.weight.grad)< 1e-7).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "gross-technical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(abs(linear2.bias.grad - linear2_b.bias.grad)< 1e-7).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-associate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tirocinio",
   "language": "python",
   "name": "tirocinio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
