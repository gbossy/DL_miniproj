{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "supported-helena",
   "metadata": {
    "id": "thermal-humanity"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "#torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "political-bloom",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INTERESTING FACT: WHEN COMPUTING THE BATCH GRADIENT PYTORCH DOES NOT TAKE THE SUM OF THE GRADIENTA OF SINGLE DATA POINTS\n",
    "#BUT THE MEAN. I LEART AT THE EXPENSE OF ABOUT 1H LOL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "searching-tract",
   "metadata": {
    "id": "found-annex"
   },
   "outputs": [],
   "source": [
    "class Parameter():\n",
    "    def __init__(self):\n",
    "        self.name = ''\n",
    "        self.data = None\n",
    "        self.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unlimited-samoa",
   "metadata": {
    "id": "therapeutic-current"
   },
   "outputs": [],
   "source": [
    "class Module(object):\n",
    "    def forward (self, *input):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backward ( self , * gradwrtoutput ) :\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_parameters( self ) :\n",
    "        return []   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "driving-grade",
   "metadata": {
    "id": "imperial-class",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Losses(object):        \n",
    "    def forward():\n",
    "        return NotImplementedError\n",
    "    def backward():\n",
    "        NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "historic-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer(object):\n",
    "    def zero_grad(self):\n",
    "        for parameter in self.param : \n",
    "            parameter.grad = 0\n",
    "            \n",
    "    def step(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "egyptian-progress",
   "metadata": {
    "id": "comfortable-calgary"
   },
   "outputs": [],
   "source": [
    "class SGD(Optimizer):\n",
    "    # this is a SGD optimizer\n",
    "    def __init__(self,lr,max_iter, parameters) :  \n",
    "        super().__init__()\n",
    "        self.eta = lr\n",
    "        self.maxStep = max_iter \n",
    "        self.param = parameters\n",
    "        self.number_step = 0\n",
    "\n",
    "    def step(self): \n",
    "        if self.number_step <=self.maxStep:\n",
    "            for parameter in self.param :\n",
    "                parameter.data = parameter.data - self.eta * parameter.grad\n",
    "            self.number_step = self.number_step + 1\n",
    "        return self.param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "external-evolution",
   "metadata": {
    "id": "asian-evanescence"
   },
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    \n",
    "    def __init__(self, input_dim, out_dim, bias = True):\n",
    "        super().__init__()\n",
    "        std = 1/math.sqrt(input_dim)\n",
    "        self.weight = Parameter()\n",
    "        self.parameters = []\n",
    "        \n",
    "        self.weight.data = torch.rand(out_dim, input_dim)\n",
    "        self.weight.data = 2*std*self.weight.data - std\n",
    "        self.weight.name = 'weight'\n",
    "        self.parameters += [self.weight]\n",
    "        \n",
    "        self.with_bias = bias\n",
    "        if bias :\n",
    "            self.bias = Parameter()\n",
    "            self.bias.data = torch.rand(out_dim)\n",
    "            self.bias.data = 2*std*self.bias.data - std\n",
    "            self.bias.data = self.bias.data.unsqueeze(0)\n",
    "            self.bias.name = 'bias'\n",
    "            self.parameters +=[self.bias]\n",
    "            \n",
    "        self.x = None\n",
    "              \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.batch_size = x.shape[0]\n",
    "        return self.x.mm(self.weight.data.T) + self.bias.data\n",
    "        \n",
    "    def backward(self, prev_grad):\n",
    "        \n",
    "        prev_grad = prev_grad.view(self.batch_size, -1, 1)\n",
    "        print(prev_grad.shape)\n",
    "        if self.x is None:\n",
    "            raise CallForwardFirst\n",
    "        \n",
    "        if self.weight.grad is None:\n",
    "            self.weight.grad = torch.zeros_like(self.weight.data)\n",
    "        \n",
    "        grad_on_batch = prev_grad.view(self.batch_size, -1, 1)*self.x.view(self.batch_size, 1, -1)\n",
    "        self.weight.grad += grad_on_batch.mean(0)\n",
    "        \n",
    "        if self.with_bias:\n",
    "            if self.bias.grad is None:\n",
    "                self.bias.grad = torch.zeros_like(self.bias.data)\n",
    "            grad_on_batch = prev_grad.view(self.batch_size, -1)\n",
    "            self.bias.grad += grad_on_batch.mean(0)\n",
    "        \n",
    "        next_grad = prev_grad.squeeze()@self.weight.data\n",
    "        return next_grad.squeeze()\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        return self.parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tracked-diagram",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11],\n",
       "         [12, 13, 14],\n",
       "         [15, 16, 17]]),\n",
       " tensor([[ 0,  3,  6,  9, 12, 15],\n",
       "         [ 1,  4,  7, 10, 13, 16],\n",
       "         [ 2,  5,  8, 11, 14, 17]]),\n",
       " tensor([[ 0,  1,  2,  3,  4,  5],\n",
       "         [ 6,  7,  8,  9, 10, 11],\n",
       "         [12, 13, 14, 15, 16, 17]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(18).view(6, 3)\n",
    "a, a.T, a.view(3, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "secret-trader",
   "metadata": {
    "id": "written-benjamin",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Tanh(Module):\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "    \n",
    "    def forward (self, x):\n",
    "        self.x = x\n",
    "        return torch.tanh(x)\n",
    "        \n",
    "    def backward ( self, prev_grad) :\n",
    "        if self.x is None:\n",
    "            raise CallForwardFirst\n",
    "            \n",
    "        def d(x):\n",
    "            return 4 * (x.exp() + x.mul(-1).exp()).pow(-2)\n",
    "        \n",
    "        return d(self.x)*prev_grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "spiritual-orchestra",
   "metadata": {
    "id": "happy-review"
   },
   "outputs": [],
   "source": [
    "class MSE(Losses):\n",
    "    # Attention! Works well only when the vectors provided are of the form [batch_size, vector dimension]\n",
    "    # Otherwise it doesn know what dimesion to pick for the mean computation\n",
    "    #I'll fix this later\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "    def forward(self, x, t):\n",
    "        self.x = x\n",
    "        self.t = t\n",
    "        return (x - t).pow(2).mean()\n",
    "    \n",
    "    def backward(self):\n",
    "        if self.x == None or self.t == None:\n",
    "            raise CallForwardFirst\n",
    "        return 2 * (self.x - self.t)/self.x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "emerging-karma",
   "metadata": {
    "id": "active-skirt"
   },
   "outputs": [],
   "source": [
    "class Sequential(object):\n",
    "    def __init__(self, modules):\n",
    "        super().__init__()\n",
    "        self.modules=modules\n",
    "        self.parameters = []\n",
    "        for m in self.modules:\n",
    "            param = m.get_parameters()\n",
    "            if param:\n",
    "                self.parameters += param\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for m in self.modules:\n",
    "            x=m.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, loss_grad):\n",
    "        x = loss_grad\n",
    "        for m in reversed(self.modules):\n",
    "            x = m.backward(x)\n",
    "            \n",
    "    def get_parameters(self):\n",
    "        return self.parameters\n",
    "\n",
    "    def set_parameters(self , params):\n",
    "        self.parameters = params\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "still-jesus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((tensor([[ 0.3294, -0.8901,  0.8070,  0.1634]]),),\n",
       " tensor([[ 0.3294, -0.8901,  0.8070,  0.1634]], grad_fn=<DivBackward0>),\n",
       " tensor([[ 1.3178, -3.5603,  3.2281,  0.6537]], grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that everything is working with loss backward\n",
    "x = torch.randn(1, 4, requires_grad = False)\n",
    "y = torch.randn(1, 4,requires_grad = False)\n",
    "\n",
    "a = x\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "\n",
    "loss_h = MSE()\n",
    "loss_b = torch.nn.MSELoss()\n",
    "\n",
    "l_h = loss_h.forward(x, y)\n",
    "l_b = loss_b(a, y)\n",
    "\n",
    "l_grad_b = torch.autograd.grad(l_b, a)\n",
    "l_grad_h = loss_h.backward()\n",
    "l_grad_b, l_grad_h, 2*(x-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "super-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now check with linear as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "broad-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5, 9, requires_grad = False)\n",
    "y = torch.randn(5, 6,requires_grad = False)\n",
    "\n",
    "linear_h = Linear(9, 6)\n",
    "linear_b = torch.torch.nn.Linear(9, 6, True)\n",
    "linear_h.weight.data = linear_b.weight.data\n",
    "linear_h.bias.data = linear_b.bias.data\n",
    "\n",
    "output_b = linear_b(x)\n",
    "l_b = loss_b(output_b, y)\n",
    "l_b.backward(retain_graph = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "limiting-handy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1115,  0.0239, -0.0051, -0.0722, -0.1696,  0.0921, -0.0631, -0.1504,\n",
       "         -0.1184],\n",
       "        [-0.2157,  0.4827,  0.0568,  0.1190, -0.4172,  0.3735,  0.5224,  0.0232,\n",
       "          0.1119],\n",
       "        [-0.1208,  0.2004, -0.0877,  0.0726, -0.2346,  0.1504, -0.0584,  0.2458,\n",
       "         -0.1080],\n",
       "        [-0.1495,  0.3429,  0.0163,  0.1191, -0.3739,  0.2459,  0.2394,  0.1706,\n",
       "          0.1176],\n",
       "        [-0.0994,  0.3140, -0.1428,  0.0422, -0.4093,  0.3527,  0.0968,  0.4471,\n",
       "          0.0470]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_h = linear_h.forward(x)\n",
    "l_h = loss_h.forward(output_h, y)\n",
    "linear_h.backward(loss_h.backward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "received-bulgaria",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0903, -0.2477,  0.1050,  0.5840, -0.1100, -0.1082],\n",
       "        [ 0.2250,  0.3841, -0.7025,  0.5687,  0.4368, -0.2147],\n",
       "        [-0.2438, -0.4224, -0.1098,  0.3458,  0.5103, -0.3355],\n",
       "        [ 0.2175,  0.0826, -0.3993,  0.2898,  0.4450, -0.4872],\n",
       "        [ 0.3394, -0.6097, -0.3983,  0.2244,  0.6062, -0.4669]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_h.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "straight-salmon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1607,  0.0050, -0.1382, -0.2027,  0.0878,  0.0800,  0.1231,  0.0859,\n",
       "           0.0090],\n",
       "         [ 0.3550, -0.0748,  0.3044, -0.0813, -0.1816, -0.1463,  0.2031, -0.1148,\n",
       "          -0.0927],\n",
       "         [ 0.1151, -0.2026,  0.0373,  0.2131, -0.1563, -0.0906, -0.3058, -0.1751,\n",
       "          -0.0623],\n",
       "         [-0.2282,  0.2699,  0.0537,  0.0323, -0.0146,  0.0618,  0.1683,  0.0161,\n",
       "           0.1387],\n",
       "         [-0.2462,  0.2890, -0.1630, -0.2163,  0.2368,  0.1671,  0.2002,  0.2428,\n",
       "           0.0778],\n",
       "         [ 0.3328, -0.2300,  0.1721,  0.2404, -0.0959, -0.1645, -0.1173, -0.1258,\n",
       "          -0.0514]]),\n",
       " tensor([[-0.1607,  0.0050, -0.1382, -0.2027,  0.0878,  0.0800,  0.1231,  0.0859,\n",
       "           0.0090],\n",
       "         [ 0.3550, -0.0748,  0.3044, -0.0813, -0.1816, -0.1463,  0.2031, -0.1148,\n",
       "          -0.0927],\n",
       "         [ 0.1151, -0.2026,  0.0373,  0.2131, -0.1563, -0.0906, -0.3058, -0.1751,\n",
       "          -0.0623],\n",
       "         [-0.2282,  0.2699,  0.0537,  0.0323, -0.0146,  0.0618,  0.1683,  0.0161,\n",
       "           0.1387],\n",
       "         [-0.2462,  0.2890, -0.1630, -0.2163,  0.2368,  0.1671,  0.2002,  0.2428,\n",
       "           0.0778],\n",
       "         [ 0.3328, -0.2300,  0.1721,  0.2404, -0.0959, -0.1645, -0.1173, -0.1258,\n",
       "          -0.0514]]),\n",
       " tensor([[True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_b.weight.grad, linear_h.weight.grad,  abs(linear_b.weight.grad - linear_h.weight.grad) < 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-liquid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fresh-circular",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 0.,  2.,  4.,  6.,  8.],\n",
       "         [ 0.,  3.,  6.,  9., 12.],\n",
       "         [ 0.,  4.,  8., 12., 16.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 0.,  2.,  4.,  6.,  8.],\n",
       "         [ 0.,  3.,  6.,  9., 12.],\n",
       "         [ 0.,  4.,  8., 12., 16.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 0.,  2.,  4.,  6.,  8.],\n",
       "         [ 0.,  3.,  6.,  9., 12.],\n",
       "         [ 0.,  4.,  8., 12., 16.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 0.,  2.,  4.,  6.,  8.],\n",
       "         [ 0.,  3.,  6.,  9., 12.],\n",
       "         [ 0.,  4.,  8., 12., 16.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 0.,  2.,  4.,  6.,  8.],\n",
       "         [ 0.,  3.,  6.,  9., 12.],\n",
       "         [ 0.,  4.,  8., 12., 16.]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity check for whats going on when computing the gradient of the weights\n",
    "l = 1.*torch.ones(5, 5)*torch.arange(5).view(1, 5)\n",
    "m = 1.*torch.ones(5, 5)*torch.arange(5).view(1, 5)\n",
    "l.view(5, -1, 1)*m.view(5, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-consumption",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "divided-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that builtin is doing the sum of the two on pytorch\n",
    "x = torch.randn(2, 9, requires_grad = False)\n",
    "y = torch.randn(2, 6,requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "defensive-kenya",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_b_1 = torch.torch.nn.Linear(9, 6, True)\n",
    "linear_b_1.weight.data = linear_b.weight.data\n",
    "linear_b_1.bias.data = linear_b.bias.data\n",
    "\n",
    "output_b_1 = linear_b_1(x[0])\n",
    "l_b_1 = loss_b(output_b_1, y[0])\n",
    "l_b_1.backward(retain_graph = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "intended-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_b_2 = torch.torch.nn.Linear(9, 6, True)\n",
    "linear_b_2.weight.data = linear_b.weight.data\n",
    "linear_b_2.bias.data = linear_b.bias.data\n",
    "\n",
    "output_b_2 = linear_b_2(x[1])\n",
    "l_b_2 = loss_b(output_b_2, y[1])\n",
    "l_b_2.backward(retain_graph = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "prerequisite-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_b_3 = torch.torch.nn.Linear(9, 6, True)\n",
    "linear_b_3.weight.data = linear_b.weight.data\n",
    "linear_b_3.bias.data = linear_b.bias.data\n",
    "\n",
    "output_b_3 = linear_b_3(x)\n",
    "l_b_3 = loss_b(output_b_3, y)\n",
    "l_b_3.backward(retain_graph = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "satisfied-bunch",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.4506e-09,  7.4506e-09, -9.3132e-09, -9.3132e-09, -2.9802e-08,\n",
       "         -1.4901e-08, -1.4901e-08,  0.0000e+00, -1.4901e-08],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  5.9605e-08, -5.9605e-08, -1.4901e-08],\n",
       "        [ 0.0000e+00,  0.0000e+00, -2.9802e-08, -2.9802e-08, -2.9802e-08,\n",
       "          5.9605e-08,  4.4703e-08,  6.7055e-08, -2.9802e-08],\n",
       "        [-2.2352e-08,  1.8626e-08, -1.4901e-08, -1.4901e-08, -2.9802e-08,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4901e-08],\n",
       "        [-2.9802e-08,  2.9802e-08, -2.2352e-08, -2.9802e-08, -1.1921e-07,\n",
       "          0.0000e+00,  0.0000e+00, -1.1921e-07, -4.4703e-08],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00, -1.4901e-08,  0.0000e+00]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(linear_b_1.weight.grad + linear_b_2.weight.grad)/2 - linear_b_3.weight.grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "pregnant-waters",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4901e-08, 0.0000e+00, 4.4703e-08, 2.9802e-08, 5.9605e-08, 0.0000e+00])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(linear_b_1.bias.grad + linear_b_2.bias.grad)/2 -  linear_b_3.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-flight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bibliographic-memory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9707)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check using sequential \n",
    "x = torch.randn(5,9, requires_grad = False)\n",
    "y = torch.randn(5,7,requires_grad = False)\n",
    "\n",
    "#handmade sequential linear + relu \n",
    "linear1 = Linear(9, 6, True)\n",
    "linear2 = Linear(6, 7, True)\n",
    "sigma1 = Tanh()\n",
    "sigma2 = Tanh()\n",
    "loss = MSE()\n",
    "\n",
    "net = Sequential([\n",
    "    linear1, \n",
    "    sigma1,\n",
    "    linear2,\n",
    "    sigma2\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "output = net.forward(x)\n",
    "loss.forward(output, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sunset-resident",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 7, 1])\n",
      "torch.Size([5, 6, 1])\n"
     ]
    }
   ],
   "source": [
    "intermediate = loss.backward()\n",
    "intermediate = sigma2.backward(intermediate)\n",
    "intermediate = linear2.backward(intermediate)\n",
    "intermediate = sigma1.backward(intermediate)\n",
    "intermediate = linear1.backward(intermediate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "assisted-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 9])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "concrete-mission",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1_b = torch.nn.Linear(9, 6)\n",
    "linear1_b.weight.data = linear1.weight.data\n",
    "linear1_b.bias.data = linear1.bias.data\n",
    "\n",
    "linear2_b = torch.nn.Linear(9, 6)\n",
    "linear2_b.weight.data = linear2.weight.data\n",
    "linear2_b.bias.data = linear2.bias.data\n",
    "\n",
    "\n",
    "\n",
    "model_b = torch.nn.Sequential(\n",
    "            linear1_b,\n",
    "            torch.nn.Tanh(),\n",
    "            linear2_b,\n",
    "            torch.nn.Tanh()\n",
    "        )\n",
    "output = model_b(x)\n",
    "l = torch.nn.MSELoss()(model_b(x), y)\n",
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "expensive-lindsay",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8626e-09, 5.5879e-09, 3.7253e-09, 2.3647e-09, 1.8626e-09, 7.4506e-09,\n",
       "         4.6566e-09, 9.3132e-10, 7.4506e-09],\n",
       "        [1.8626e-09, 2.0256e-08, 2.9802e-08, 9.3132e-09, 7.4506e-09, 7.4506e-09,\n",
       "         2.5146e-08, 7.4506e-09, 2.2352e-08],\n",
       "        [4.0745e-10, 5.1223e-09, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4901e-08,\n",
       "         5.5879e-09, 1.1176e-08, 3.2596e-09],\n",
       "        [7.4506e-09, 5.5879e-09, 1.8626e-08, 4.6566e-09, 7.4506e-09, 9.3132e-09,\n",
       "         7.4506e-09, 5.5879e-09, 6.1846e-10],\n",
       "        [5.5879e-09, 1.6764e-08, 2.9802e-08, 1.4901e-08, 2.2352e-08, 2.9802e-08,\n",
       "         2.6077e-08, 2.2352e-08, 1.1176e-08],\n",
       "        [0.0000e+00, 7.4506e-09, 8.3819e-09, 1.8626e-09, 3.7253e-09, 7.4506e-09,\n",
       "         1.8626e-09, 5.5879e-09, 6.9849e-09]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(linear1.weight.grad - linear1_b.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "smart-freedom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.7253e-09, 2.5320e-08, 1.4901e-08, 7.4506e-09, 2.6077e-08, 3.7253e-09]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(linear1.bias.grad - linear1_b.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "conditional-litigation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4901e-08, 7.4506e-09, 5.1223e-09, 3.7253e-09, 5.5879e-09, 1.8626e-09],\n",
       "        [3.7253e-09, 7.4506e-09, 3.7253e-09, 7.4506e-09, 3.7253e-09, 7.4506e-09],\n",
       "        [9.3132e-10, 1.8626e-09, 3.7253e-09, 0.0000e+00, 3.7253e-09, 1.8626e-09],\n",
       "        [3.7253e-09, 2.9802e-08, 7.4506e-09, 7.4506e-09, 3.7253e-09, 3.7253e-09],\n",
       "        [9.7789e-09, 3.7253e-09, 3.7253e-09, 0.0000e+00, 3.7253e-09, 5.5879e-09],\n",
       "        [3.7253e-09, 0.0000e+00, 3.7253e-09, 1.8626e-09, 3.7253e-09, 0.0000e+00],\n",
       "        [3.7253e-09, 3.7253e-09, 5.5879e-09, 9.3132e-10, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(linear2.weight.grad - linear2_b.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "brief-interface",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8626e-08, 1.4901e-08, 1.4901e-08, 1.8626e-08, 1.8626e-08, 0.0000e+00,\n",
       "         1.4901e-08]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(linear2.bias.grad - linear2_b.bias.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tirocinio",
   "language": "python",
   "name": "tirocinio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
