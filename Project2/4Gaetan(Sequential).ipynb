{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x1ccad0aff08>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_linear(torch.nn.Linear):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__(d_in, d_out)\n",
    "    \n",
    "    def param(self):\n",
    "        par = []\n",
    "        par += [self.weight.data]\n",
    "        par += [self.bias.data]\n",
    "        return par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.2419,  0.3790,  0.2020, -0.1787, -0.2426],\n",
       "         [ 0.4184,  0.1176, -0.2746, -0.1671, -0.1089],\n",
       "         [-0.1925,  0.4324, -0.2243,  0.1662, -0.2713],\n",
       "         [-0.0015, -0.2377,  0.4461,  0.3857,  0.2721],\n",
       "         [-0.0340,  0.1860,  0.2836,  0.2742,  0.1191],\n",
       "         [-0.2894,  0.4272,  0.1985, -0.4200, -0.0574]]),\n",
       " tensor([-0.2411,  0.3310, -0.0837, -0.1088,  0.1910, -0.1517]),\n",
       " <generator object Module.parameters at 0x000001CCB0BE70C8>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = my_linear(5, 6)\n",
    "linear.weight.data, linear.bias.data, linear.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.2419,  0.3790,  0.2020, -0.1787, -0.2426],\n",
       "         [ 0.4184,  0.1176, -0.2746, -0.1671, -0.1089],\n",
       "         [-0.1925,  0.4324, -0.2243,  0.1662, -0.2713],\n",
       "         [-0.0015, -0.2377,  0.4461,  0.3857,  0.2721],\n",
       "         [-0.0340,  0.1860,  0.2836,  0.2742,  0.1191],\n",
       "         [-0.2894,  0.4272,  0.1985, -0.4200, -0.0574]]),\n",
       " tensor([-0.2411,  0.3310, -0.0837, -0.1088,  0.1910, -0.1517])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = linear.param()\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), tensor(True))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(parameters[0] == linear.weight.data).all(), (parameters[1] == linear.bias.data).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can define a class Sequential that take as parameters as instance\n",
    "# of my_linear and an instance of the standart torch.nn.ReLU() and computes \n",
    "# has a method to compute the combined gradient\n",
    "class Sequential(object):\n",
    "    def __init__(self, modules):\n",
    "        super().__init__()\n",
    "        self.modules=modules\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for m in self.modules:\n",
    "            x=m.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self,weights,values,dl_dw,target):\n",
    "        xn=values[-1]\n",
    "        dl_dx=[]\n",
    "        dl_dx.append(dloss(x_n,t))\n",
    "        for i in range(len(self.modules)).reversed():\n",
    "            m=self.modules[i]\n",
    "            dl_dx.append(m.backwardoutput(dl_dx[-1],values[i]))#backward is implemented for each module\n",
    "        for i in range(len(self.modules)).reversed():\n",
    "            m=self.modules[i]\n",
    "            dl_dw=m.backwardweights(dl_dw,dl_dx[i+1],values[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
