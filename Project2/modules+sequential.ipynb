{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "thermal-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "#torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "therapeutic-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module(object):\n",
    "    def forward (self, *input):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backward ( self , * gradwrtoutput ) :\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_parameters( self ) :\n",
    "        return []   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "imperial-class",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Losses(object):        \n",
    "    def forward():\n",
    "        return NotImplementedError\n",
    "    def backward():\n",
    "        NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "comfortable-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizers(object):\n",
    "    def step():\n",
    "        return NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "found-annex",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameter():\n",
    "    def __init__(self):\n",
    "        self.name = ''\n",
    "        self.data = None\n",
    "        self.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "asian-evanescence",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    \n",
    "    def __init__(self, input_dim, out_dim, bias = True):\n",
    "        super().__init__()\n",
    "        std = 1/math.sqrt(input_dim)\n",
    "        self.weight = Parameter()\n",
    "        self.parameters = []\n",
    "        \n",
    "        self.weight.data = torch.rand(out_dim, input_dim)\n",
    "        self.weight.data = 2*std*self.weight.data - std\n",
    "        self.weight.name = 'weight'\n",
    "        self.parameters += [self.weight]\n",
    "        \n",
    "        self.with_bias = bias\n",
    "        if bias :\n",
    "            self.bias = Parameter()\n",
    "            self.bias.data = torch.rand(out_dim)\n",
    "            self.bias.data = 2*std*self.bias.data - std\n",
    "            self.bias.name = 'bias'\n",
    "            self.parameters +=[self.bias]\n",
    "            \n",
    "        self.x = None\n",
    "              \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return self.weight.data.mv(x) + self.bias.data\n",
    "        \n",
    "    def backward(self, prev_grad):\n",
    "        \n",
    "        prev_grad = prev_grad.view(-1, 1)\n",
    "        if self.x is None:\n",
    "            raise CallForwardFirst\n",
    "        \n",
    "        if self.weight.grad is None:\n",
    "            self.weight.grad = torch.zeros_like(self.weight.data)\n",
    "        \n",
    "        self.weight.grad += prev_grad.view(-1, 1)*self.x.view(1, -1)\n",
    "        \n",
    "        if self.with_bias:\n",
    "            if self.bias.grad is None:\n",
    "                self.bias.grad = torch.zeros_like(self.bias.data)\n",
    "            self.bias.grad += prev_grad.view(-1)\n",
    "        \n",
    "        next_grad = prev_grad.view(1, -1)@self.weight.data\n",
    "        next_grad = next_grad.view(-1, 1)\n",
    "        return next_grad\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        return self.parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "written-benjamin",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Tanh(Module):\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "    \n",
    "    def forward (self, x):\n",
    "        self.x = x\n",
    "        return torch.tanh(x)\n",
    "        \n",
    "    def backward ( self, prev_grad) :\n",
    "        if self.x is None:\n",
    "            raise CallForwardFirst\n",
    "            \n",
    "        def d(x):\n",
    "            return 4 * (x.exp() + x.mul(-1).exp()).pow(-2)\n",
    "        \n",
    "        return d(self.x)*prev_grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "happy-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(Losses):\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "    def forward(self, x, t):\n",
    "        self.x = x\n",
    "        self.t = t\n",
    "        return (x - t).pow(2).mean()\n",
    "    \n",
    "    def backward(self):\n",
    "        if self.x == None or self.t == None:\n",
    "            raise CallForwardFirst\n",
    "        return 2 * (self.x - self.t)/len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "active-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential(object):\n",
    "    def __init__(self, modules):\n",
    "        super().__init__()\n",
    "        self.modules=modules\n",
    "        self.parameters = []\n",
    "        for m in self.modules:\n",
    "            param = m.get_parameters()\n",
    "            if param:\n",
    "                self.parameters += param\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for m in self.modules:\n",
    "            x=m.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, loss_grad):\n",
    "        x = loss_grad\n",
    "        for m in reversed(self.modules):\n",
    "            x = m.backward(x)\n",
    "            \n",
    "    def get_parameters(self):\n",
    "        return self.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "legal-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(9, requires_grad = False)\n",
    "y = torch.randn(6,requires_grad = False)\n",
    "\n",
    "#handmade sequential linear + relu \n",
    "linear = Linear(9, 6, True)\n",
    "sigma = Tanh()\n",
    "loss = MSE()\n",
    "\n",
    "net = Sequential([\n",
    "    linear, \n",
    "    sigma\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "julian-memory",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias\n",
      "weight\n"
     ]
    }
   ],
   "source": [
    "for param in reversed(net.get_parameters()):\n",
    "    print(param.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "arbitrary-customer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = net.forward(x)\n",
    "loss.forward(output, y)\n",
    "\n",
    "net.backward(loss.backward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "russian-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing with builtin methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "agricultural-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_linear = torch.nn.Linear(9, 6, True)\n",
    "b_linear.weight.data = linear.weight.data\n",
    "b_linear.bias.data = linear.bias.data\n",
    "l = torch.nn.MSELoss()(torch.tanh(b_linear(x)), y)\n",
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "biological-savage",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1662,  0.0132, -0.2021,  0.1636,  0.0089, -0.1216,  0.0104,  0.0379,\n",
       "          -0.0240],\n",
       "         [ 1.2942,  0.1027, -1.5732,  1.2739,  0.0691, -0.9469,  0.0809,  0.2954,\n",
       "          -0.1872],\n",
       "         [ 0.4139,  0.0328, -0.5032,  0.4074,  0.0221, -0.3029,  0.0259,  0.0945,\n",
       "          -0.0599],\n",
       "         [ 0.1593,  0.0126, -0.1937,  0.1568,  0.0085, -0.1166,  0.0100,  0.0364,\n",
       "          -0.0230],\n",
       "         [ 0.4564,  0.0362, -0.5548,  0.4493,  0.0244, -0.3340,  0.0285,  0.1042,\n",
       "          -0.0660],\n",
       "         [ 0.3175,  0.0252, -0.3859,  0.3125,  0.0170, -0.2323,  0.0199,  0.0725,\n",
       "          -0.0459]]),\n",
       " tensor([[ 0.1662,  0.0132, -0.2021,  0.1636,  0.0089, -0.1216,  0.0104,  0.0379,\n",
       "          -0.0240],\n",
       "         [ 1.2942,  0.1027, -1.5732,  1.2739,  0.0691, -0.9469,  0.0809,  0.2954,\n",
       "          -0.1872],\n",
       "         [ 0.4139,  0.0328, -0.5032,  0.4074,  0.0221, -0.3029,  0.0259,  0.0945,\n",
       "          -0.0599],\n",
       "         [ 0.1593,  0.0126, -0.1937,  0.1568,  0.0085, -0.1166,  0.0100,  0.0364,\n",
       "          -0.0230],\n",
       "         [ 0.4564,  0.0362, -0.5548,  0.4493,  0.0244, -0.3340,  0.0285,  0.1042,\n",
       "          -0.0660],\n",
       "         [ 0.3175,  0.0252, -0.3859,  0.3125,  0.0170, -0.2323,  0.0199,  0.0725,\n",
       "          -0.0459]]),\n",
       " tensor(1.1921e-07))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_linear.weight.grad, linear.weight.grad,  abs(b_linear.weight.grad - linear.weight.grad).max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "exact-rotation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0721, 0.5614, 0.1796, 0.0691, 0.1980, 0.1377]),\n",
       " tensor([0.0721, 0.5614, 0.1796, 0.0691, 0.1980, 0.1377]),\n",
       " tensor(5.9605e-08))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_linear.bias.grad, linear.bias.grad,  abs(b_linear.bias.grad - linear.bias.grad).max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tirocinio",
   "language": "python",
   "name": "tirocinio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
